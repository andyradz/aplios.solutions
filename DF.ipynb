{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andyradz/aplios.solutions/blob/master/DF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGXJRQ3jnJ-s"
      },
      "source": [
        "# DataFame"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "143RKsrU6yWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pyspark"
      ],
      "metadata": {
        "id": "0MuQgsuC6oUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip3 install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "us3bxjElnbZX",
        "outputId": "9e413e1d-59b9-43af-b1a3-e357c1bd5b23"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.9/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317145 sha256=caff527bd4055da226714b03888fd8e91cf67b60e360ed5c2e3dab1e8f6cc40b\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/34/a4/159aa12d0a510d5ff7c8f0220abbea42e5d81ecf588c4fd884\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://drive.google.com/uc?id=1G9H9BFtcQrokludqfvDv8sz58DwT7Mn6&export=download -O data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSMpixJvxvBf",
        "outputId": "47815008-2b2d-468b-95b5-29cb38976c76"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: -O: command not found\n",
            "--2023-04-14 08:01:22--  https://drive.google.com/uc?id=1G9H9BFtcQrokludqfvDv8sz58DwT7Mn6\n",
            "Resolving drive.google.com (drive.google.com)... 173.194.192.138, 173.194.192.102, 173.194.192.101, ...\n",
            "Connecting to drive.google.com (drive.google.com)|173.194.192.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-10-1o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/lhmdckcroh1mlourghlq3cpaqhi55jpj/1681459275000/05017911732949556247/*/1G9H9BFtcQrokludqfvDv8sz58DwT7Mn6?uuid=c5d2f89e-0301-4823-b64a-36b7c0d27bc4 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-04-14 08:01:27--  https://doc-10-1o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/lhmdckcroh1mlourghlq3cpaqhi55jpj/1681459275000/05017911732949556247/*/1G9H9BFtcQrokludqfvDv8sz58DwT7Mn6?uuid=c5d2f89e-0301-4823-b64a-36b7c0d27bc4\n",
            "Resolving doc-10-1o-docs.googleusercontent.com (doc-10-1o-docs.googleusercontent.com)... 173.194.198.132, 2607:f8b0:4001:c1c::84\n",
            "Connecting to doc-10-1o-docs.googleusercontent.com (doc-10-1o-docs.googleusercontent.com)|173.194.198.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 25234788 (24M) [application/zip]\n",
            "Saving to: ‘uc?id=1G9H9BFtcQrokludqfvDv8sz58DwT7Mn6.1’\n",
            "\n",
            "uc?id=1G9H9BFtcQrok 100%[===================>]  24.07M   109MB/s    in 0.2s    \n",
            "\n",
            "2023-04-14 08:01:27 (109 MB/s) - ‘uc?id=1G9H9BFtcQrokludqfvDv8sz58DwT7Mn6.1’ saved [25234788/25234788]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! 7z x data.zip -o* -aoa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0T1X3JhyemJ",
        "outputId": "e04d3305-a5a4-41d9-960e-49ad3e15ed62"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 25234788 bytes (25 MiB)\n",
            "\n",
            "Extracting archive: data.zip\n",
            "--\n",
            "Path = data.zip\n",
            "Type = zip\n",
            "Physical Size = 25234788\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b 18% - 2017-fordgobike-tripdata.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% - 2017-fordgobike-tripdata.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 62% - 2017-fordgobike-tripdata.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 79% 4 - Badges.xml\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 99% 8 - postgresql-42.2.18.jar\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Folders: 1\n",
            "Files: 25\n",
            "Size:       167863139\n",
            "Compressed: 25234788\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "uNBg_33Ss1zS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip freeze | grep -i spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBcik0KC-CVN",
        "outputId": "7bbcca64-2a9e-4214-bdb2-f7c88c96e4fa"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pyspark==3.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aP7Gls4fnJ-u"
      },
      "source": [
        "https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "DtLUIHQZnJ-u"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession#, SparkConf\n",
        "from pyspark import SparkConf\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql import functions as f\n",
        "\n",
        "conf = SparkConf()\n",
        "conf.set(\"spark.sql.catalog.spark_catalog\", \"org.apache.iceberg.spark.SparkSessionCatalog\")\n",
        "#.conf(conf) \\\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName('app') \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lq5RKxIYnJ-v"
      },
      "source": [
        "## Tworzenie DataFrame'u"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwBpH-M1nJ-v"
      },
      "source": [
        "### Kolekcja Row'ów"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "XXAeMPOrnJ-v"
      },
      "outputs": [],
      "source": [
        "person1 = Row(age=32, name='Greg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUviZGecnJ-v",
        "outputId": "7c65fc8b-a0a7-4b24-b730-025a8b2f0c43"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(age=32, name='Greg')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "person1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQkq1lEKnJ-v",
        "outputId": "c01a520a-c5c6-40cf-e11f-f4d2320ce9f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Greg', 32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "person1.name, person1.age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOG6GQR1nJ-w",
        "outputId": "978bb3ae-52d7-4d16-b5c7-32835160aeed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "person1['age']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "R-MWZIAunJ-w",
        "outputId": "4772acb0-47dd-4cda-d47a-19636d426b1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Greg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "person1[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxdwargdnJ-w",
        "outputId": "5d3ce971-37eb-4dbd-e0f4-092216c7c7b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "'age' in person1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "zC3otVgCnJ-w"
      },
      "outputs": [],
      "source": [
        "newPerson = Row(\"age\", \"name\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "n_zJ_D9NnJ-w"
      },
      "outputs": [],
      "source": [
        "person2 = newPerson(24, 'Alice')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpN7n1VQnJ-x",
        "outputId": "ac44839c-3e10-487a-9fd6-3b523ac71bb4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(age=24, name='Alice')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "person2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "v7x2KzNCnJ-x"
      },
      "outputs": [],
      "source": [
        "person3 = newPerson(None, None)\n",
        "person4 = newPerson(33, None)\n",
        "person5 = newPerson(None, 'Peter')\n",
        "person6 = newPerson(32, 'Peter')\n",
        "person7 = newPerson(40, 'Greg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "stkgu5YOnJ-x"
      },
      "outputs": [],
      "source": [
        "peopleDF = spark.createDataFrame([person1, person2, person3, person4, \n",
        "                                  person5, person6, person7])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c55U2z4pnJ-x",
        "outputId": "9dffbbce-df56-4332-af4e-8c0f71c69266"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+\n",
            "| age| name|\n",
            "+----+-----+\n",
            "|  32| Greg|\n",
            "|  24|Alice|\n",
            "|null| null|\n",
            "|  33| null|\n",
            "|null|Peter|\n",
            "|  32|Peter|\n",
            "|  40| Greg|\n",
            "+----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "peopleDF.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKSKAaawnJ-x"
      },
      "source": [
        "### Inne lokalne kolekcje"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKU5YsUenJ-x"
      },
      "source": [
        "Typy danych: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#data-types\n",
        "\n",
        "Kilka podstawowych: IntegerType, DoubleType, FloatType, StringType, BooleanType, NullType"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "eAXYvAhknJ-y"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import IntegerType, StringType, StructType, StructField"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "0B30f0rnnJ-y"
      },
      "outputs": [],
      "source": [
        "# definicja schematu\n",
        "# StructType ~ Row\n",
        "schema = StructType([StructField(\"V1\", IntegerType()), StructField(\"V2\", StringType())])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "ylB9cpKFnJ-y"
      },
      "outputs": [],
      "source": [
        "# lokalna kolekcja - lista list\n",
        "df = spark.createDataFrame([(1,2),(3,4)], schema)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgNWSKsEnJ-y",
        "outputId": "ac00dabc-c5ae-4023-a727-0cfd3d229a3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+\n",
            "| V1| V2|\n",
            "+---+---+\n",
            "|  1|  2|\n",
            "|  3|  4|\n",
            "+---+---+\n",
            "\n",
            "root\n",
            " |-- V1: integer (nullable = true)\n",
            " |-- V2: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show()\n",
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v90q5k0CnJ-y"
      },
      "source": [
        "### RDD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkGjeHW1nJ-y"
      },
      "source": [
        "Przechodzenie RDD <-> DF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7POb6zInJ-y",
        "outputId": "e4c6b94d-9af1-4c6e-a69b-6202852cb3be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "type(peopleDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvwMb0ArnJ-y",
        "outputId": "6d1f1c00-9801-4097-ac4b-949296d771fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+\n",
            "| age| name|\n",
            "+----+-----+\n",
            "|  32| Greg|\n",
            "|  24|Alice|\n",
            "|null| null|\n",
            "|  33| null|\n",
            "|null|Peter|\n",
            "|  32|Peter|\n",
            "|  40| Greg|\n",
            "+----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "peopleDF.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJr0QoIEnJ-z"
      },
      "source": [
        "DF -> RDD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKrhzK9fnJ-z",
        "outputId": "e2b0554a-937b-42ba-9d0f-892290e5bba0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.rdd.RDD"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "peopleRDD = peopleDF.rdd\n",
        "type(peopleRDD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ts-3DcTcnJ-z",
        "outputId": "0ca50341-ad34-4663-bfdc-8259147f9a53"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(age=32, name='Greg'),\n",
              " Row(age=24, name='Alice'),\n",
              " Row(age=None, name=None),\n",
              " Row(age=33, name=None),\n",
              " Row(age=None, name='Peter'),\n",
              " Row(age=32, name='Peter'),\n",
              " Row(age=40, name='Greg')]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "peopleRDD.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMTEaNZ8nJ-z",
        "outputId": "68a34f48-8e22-4eb6-ba50-4cd586ece0b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(32, 'Greg'),\n",
              " (24, 'Alice'),\n",
              " (None, 'X'),\n",
              " (33, 'X'),\n",
              " (None, 'Peter'),\n",
              " (32, 'Peter'),\n",
              " (40, 'Greg')]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "peopleRDD.map(tuple).mapValues(lambda x: \"X\" if x is None else x).collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgVnJBKEnJ-0"
      },
      "source": [
        "RDD -> DF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEgQssi2nJ-0"
      },
      "outputs": [],
      "source": [
        "peopleRDD.toDF().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z72j6RvbnJ-0"
      },
      "outputs": [],
      "source": [
        "peopleRDD.map(tuple).toDF().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMy53TpNnJ-0"
      },
      "outputs": [],
      "source": [
        "peopleRDD.map(tuple).toDF().dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5SMioxcnJ-0"
      },
      "outputs": [],
      "source": [
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qztecq2nJ-1"
      },
      "outputs": [],
      "source": [
        "tupRDD = sc.parallelize([(x, x+1) for x in range(5)])\n",
        "tupRDD.toDF().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6j821Xc1nJ-1"
      },
      "outputs": [],
      "source": [
        "# do toDF można podać schemat\n",
        "schema = StructType([StructField(\"A\", IntegerType()), StructField(\"B\", StringType())])\n",
        "tupRDD.toDF(schema).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64O617VmnJ-2"
      },
      "source": [
        "> **TODO**: Stwórz DF z 3 wierszami i 3 kolumnami - dwie typu string, jedna numeryczna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "d_8d0UK1nJ-2"
      },
      "outputs": [],
      "source": [
        "schema = StructType([StructField(\"Name\", StringType()), StructField(\"Sureame\", StringType()), StructField(\"Age\", IntegerType())])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WTLspC6nJ-2",
        "outputId": "45f41372-e9cf-47b5-943b-33a0faa9ed73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+---+\n",
            "|   Name|Sureame|Age|\n",
            "+-------+-------+---+\n",
            "|Andrzej|      R| 12|\n",
            "| Hubert|      W| 34|\n",
            "| Marcin|      P| 34|\n",
            "+-------+-------+---+\n",
            "\n",
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Sureame: string (nullable = true)\n",
            " |-- Age: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "personsDF=spark.createDataFrame([('Andrzej', 'R', 12),('Hubert', 'W', 34),('Marcin', 'P', 34)], schema)\n",
        "personsDF.show()\n",
        "personsDF.printSchema()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NE5o--YnJ-2"
      },
      "source": [
        "### Plik\n",
        "\n",
        "Obsługiwane: text, csv, [nd]json, orc, parquet, avro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "OZ5Cgv3dnJ-3"
      },
      "outputs": [],
      "source": [
        "empHist = spark.read.parquet(\"data/salary_hist\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNUNuH-HnJ-3",
        "outputId": "859985f3-55ca-49b6-8a1b-15dc115f7e91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+----+-------+\n",
            "| name| salary|year|company|\n",
            "+-----+-------+----+-------+\n",
            "|Alice|4404.23|2005|      X|\n",
            "|Alice| 3000.0|2005|      Y|\n",
            "|Alice|4780.34|2006|      X|\n",
            "|Alice|4881.72|2007|      X|\n",
            "|Alice|5280.86|2008|      X|\n",
            "|Alice|5976.68|2009|      Z|\n",
            "|Alice|6320.14|2010|      Z|\n",
            "|Betty|4138.01|2005|      Y|\n",
            "|Betty|4376.94|2006|      Y|\n",
            "|Betty|5117.68|2007|      X|\n",
            "|Betty|5630.26|2008|      X|\n",
            "|Betty|6222.57|2009|      X|\n",
            "|Betty|6623.97|2010|      X|\n",
            "|Chris|3601.42|2005|      X|\n",
            "|Chris|4015.66|2006|      X|\n",
            "|Chris|4304.73|2007|      X|\n",
            "|Chris|4650.33|2008|      X|\n",
            "|Chris|4932.86|2009|      X|\n",
            "|Chris|5869.98|2010|      X|\n",
            "|  Dan|4262.75|2005|      Y|\n",
            "+-----+-------+----+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "empHist.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBTqGvNUnJ-3",
        "outputId": "91874c52-e187-4721-d28b-792a48e68f7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "*(1) ColumnarToRow\n",
            "+- FileScan parquet [name#280,salary#281,year#282,company#283] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/content/data/salary_hist], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<name:string,salary:double,year:int,company:string>\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "empHist.explain()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0pIRnUKnJ-3",
        "outputId": "944fb67c-4ad8-4d88-9e40-c153e6ebecf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "*(1) ColumnarToRow\n",
            "+- FileScan parquet [name#280] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/content/data/salary_hist], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<name:string>\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "empHist.select(\"name\").explain()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4MwF8YenJ-3"
      },
      "source": [
        "Źródło danych: https://archive.ics.uci.edu/ml/datasets/adult"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! head data/adult.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBgJctLlIy2u",
        "outputId": "2000cf07-418b-4bdb-d539-2f7586d0948a"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39, State-gov, 77516, Bachelors, 13, Never-married, Adm-clerical, Not-in-family, White, Male, 2174, 0, 40, United-States, <=50K\n",
            "50, Self-emp-not-inc, 83311, Bachelors, 13, Married-civ-spouse, Exec-managerial, Husband, White, Male, 0, 0, 13, United-States, <=50K\n",
            "38, Private, 215646, HS-grad, 9, Divorced, Handlers-cleaners, Not-in-family, White, Male, 0, 0, 40, United-States, <=50K\n",
            "53, Private, 234721, 11th, 7, Married-civ-spouse, Handlers-cleaners, Husband, Black, Male, 0, 0, 40, United-States, <=50K\n",
            "28, Private, 338409, Bachelors, 13, Married-civ-spouse, Prof-specialty, Wife, Black, Female, 0, 0, 40, Cuba, <=50K\n",
            "37, Private, 284582, Masters, 14, Married-civ-spouse, Exec-managerial, Wife, White, Female, 0, 0, 40, United-States, <=50K\n",
            "49, Private, 160187, 9th, 5, Married-spouse-absent, Other-service, Not-in-family, Black, Female, 0, 0, 16, Jamaica, <=50K\n",
            "52, Self-emp-not-inc, 209642, HS-grad, 9, Married-civ-spouse, Exec-managerial, Husband, White, Male, 0, 0, 45, United-States, >50K\n",
            "31, Private, 45781, Masters, 14, Never-married, Prof-specialty, Not-in-family, White, Female, 14084, 0, 50, United-States, >50K\n",
            "42, Private, 159449, Bachelors, 13, Married-civ-spouse, Exec-managerial, Husband, White, Male, 5178, 0, 40, United-States, >50K\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "b1O-YOIinJ-3"
      },
      "outputs": [],
      "source": [
        "# csv\n",
        "adultDF = spark.read.csv(\"data/adult.data\", inferSchema=True, ignoreLeadingWhiteSpace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1FOIwcCnJ-3",
        "outputId": "edce440d-f712-423e-fa54-2cd52105dd1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------------+------+------------+---+--------------------+-----------------+-------------+------------------+------+-----+----+----+-------------+-----+\n",
            "|_c0|             _c1|   _c2|         _c3|_c4|                 _c5|              _c6|          _c7|               _c8|   _c9| _c10|_c11|_c12|         _c13| _c14|\n",
            "+---+----------------+------+------------+---+--------------------+-----------------+-------------+------------------+------+-----+----+----+-------------+-----+\n",
            "| 39|       State-gov| 77516|   Bachelors| 13|       Never-married|     Adm-clerical|Not-in-family|             White|  Male| 2174|   0|  40|United-States|<=50K|\n",
            "| 50|Self-emp-not-inc| 83311|   Bachelors| 13|  Married-civ-spouse|  Exec-managerial|      Husband|             White|  Male|    0|   0|  13|United-States|<=50K|\n",
            "| 38|         Private|215646|     HS-grad|  9|            Divorced|Handlers-cleaners|Not-in-family|             White|  Male|    0|   0|  40|United-States|<=50K|\n",
            "| 53|         Private|234721|        11th|  7|  Married-civ-spouse|Handlers-cleaners|      Husband|             Black|  Male|    0|   0|  40|United-States|<=50K|\n",
            "| 28|         Private|338409|   Bachelors| 13|  Married-civ-spouse|   Prof-specialty|         Wife|             Black|Female|    0|   0|  40|         Cuba|<=50K|\n",
            "| 37|         Private|284582|     Masters| 14|  Married-civ-spouse|  Exec-managerial|         Wife|             White|Female|    0|   0|  40|United-States|<=50K|\n",
            "| 49|         Private|160187|         9th|  5|Married-spouse-ab...|    Other-service|Not-in-family|             Black|Female|    0|   0|  16|      Jamaica|<=50K|\n",
            "| 52|Self-emp-not-inc|209642|     HS-grad|  9|  Married-civ-spouse|  Exec-managerial|      Husband|             White|  Male|    0|   0|  45|United-States| >50K|\n",
            "| 31|         Private| 45781|     Masters| 14|       Never-married|   Prof-specialty|Not-in-family|             White|Female|14084|   0|  50|United-States| >50K|\n",
            "| 42|         Private|159449|   Bachelors| 13|  Married-civ-spouse|  Exec-managerial|      Husband|             White|  Male| 5178|   0|  40|United-States| >50K|\n",
            "| 37|         Private|280464|Some-college| 10|  Married-civ-spouse|  Exec-managerial|      Husband|             Black|  Male|    0|   0|  80|United-States| >50K|\n",
            "| 30|       State-gov|141297|   Bachelors| 13|  Married-civ-spouse|   Prof-specialty|      Husband|Asian-Pac-Islander|  Male|    0|   0|  40|        India| >50K|\n",
            "| 23|         Private|122272|   Bachelors| 13|       Never-married|     Adm-clerical|    Own-child|             White|Female|    0|   0|  30|United-States|<=50K|\n",
            "| 32|         Private|205019|  Assoc-acdm| 12|       Never-married|            Sales|Not-in-family|             Black|  Male|    0|   0|  50|United-States|<=50K|\n",
            "| 40|         Private|121772|   Assoc-voc| 11|  Married-civ-spouse|     Craft-repair|      Husband|Asian-Pac-Islander|  Male|    0|   0|  40|            ?| >50K|\n",
            "| 34|         Private|245487|     7th-8th|  4|  Married-civ-spouse| Transport-moving|      Husband|Amer-Indian-Eskimo|  Male|    0|   0|  45|       Mexico|<=50K|\n",
            "| 25|Self-emp-not-inc|176756|     HS-grad|  9|       Never-married|  Farming-fishing|    Own-child|             White|  Male|    0|   0|  35|United-States|<=50K|\n",
            "| 32|         Private|186824|     HS-grad|  9|       Never-married|Machine-op-inspct|    Unmarried|             White|  Male|    0|   0|  40|United-States|<=50K|\n",
            "| 38|         Private| 28887|        11th|  7|  Married-civ-spouse|            Sales|      Husband|             White|  Male|    0|   0|  50|United-States|<=50K|\n",
            "| 43|Self-emp-not-inc|292175|     Masters| 14|            Divorced|  Exec-managerial|    Unmarried|             White|Female|    0|   0|  45|United-States| >50K|\n",
            "+---+----------------+------+------------+---+--------------------+-----------------+-------------+------------------+------+-----+----+----+-------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "adultDF.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXqja8dYnJ-4",
        "outputId": "6fa8e19a-d76b-453a-e984-32513033f67b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(_c0=39, _c1='State-gov', _c2=77516, _c3='Bachelors', _c4=13, _c5='Never-married', _c6='Adm-clerical', _c7='Not-in-family', _c8='White', _c9='Male', _c10=2174, _c11=0, _c12=40, _c13='United-States', _c14='<=50K')]"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "adultDF.take(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "7XRYIWwUnJ-4"
      },
      "outputs": [],
      "source": [
        "col_names = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\",\"marital-status\", \"occupation\", \n",
        "             \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \n",
        "             \"native-country\", \"earnings\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "ts-BfwopnJ-4"
      },
      "outputs": [],
      "source": [
        "adultDF = adultDF.toDF(*col_names).drop(\"fnlwgt\").dropna(\"any\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUieVb6AnJ-4",
        "outputId": "0f6557a1-5f5d-44bb-c954-bcbde31f79d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-RECORD 0----------------------------\n",
            " age            | 39                 \n",
            " workclass      | State-gov          \n",
            " education      | Bachelors          \n",
            " education-num  | 13                 \n",
            " marital-status | Never-married      \n",
            " occupation     | Adm-clerical       \n",
            " relationship   | Not-in-family      \n",
            " race           | White              \n",
            " sex            | Male               \n",
            " capital-gain   | 2174               \n",
            " capital-loss   | 0                  \n",
            " hours-per-week | 40                 \n",
            " native-country | United-States      \n",
            " earnings       | <=50K              \n",
            "-RECORD 1----------------------------\n",
            " age            | 50                 \n",
            " workclass      | Self-emp-not-inc   \n",
            " education      | Bachelors          \n",
            " education-num  | 13                 \n",
            " marital-status | Married-civ-spouse \n",
            " occupation     | Exec-managerial    \n",
            " relationship   | Husband            \n",
            " race           | White              \n",
            " sex            | Male               \n",
            " capital-gain   | 0                  \n",
            " capital-loss   | 0                  \n",
            " hours-per-week | 13                 \n",
            " native-country | United-States      \n",
            " earnings       | <=50K              \n",
            "-RECORD 2----------------------------\n",
            " age            | 38                 \n",
            " workclass      | Private            \n",
            " education      | HS-grad            \n",
            " education-num  | 9                  \n",
            " marital-status | Divorced           \n",
            " occupation     | Handlers-cleaners  \n",
            " relationship   | Not-in-family      \n",
            " race           | White              \n",
            " sex            | Male               \n",
            " capital-gain   | 0                  \n",
            " capital-loss   | 0                  \n",
            " hours-per-week | 40                 \n",
            " native-country | United-States      \n",
            " earnings       | <=50K              \n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "adultDF.show(3, vertical=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdB3u9ggnJ-4"
      },
      "source": [
        "## Zapisywanie DataFrame'u"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0z-AtOzCnJ-4"
      },
      "outputs": [],
      "source": [
        "#peopleDF.write.csv(\"...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvMQuJAQnJ-4"
      },
      "outputs": [],
      "source": [
        "#peopleDF.write.parquet(\"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBB_oqO3nJ-4"
      },
      "source": [
        "**Partycjonowanie** - tworzenie podkatalogów w katalogu z danymi w oparciu o unikatowe wartości we wskazanej kolumnie/kolumnach - zapytania dotyczące tylko jednego z poziomów zmiennej na podstwie której dokonano partycjonowania będą musiały przeskanować jedynie fragment danych a nie całość\n",
        "\n",
        "**Bucketing** - sposób na rozdystrybuowanie/organizację danych na wskazaną (stałą) liczbę buketów, każdy bucket to osobny plik, przypisanie rekordu do bucketu wynika z hasha wartości wskazanej kolumny/kolumn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "N9zHQORfnJ-4"
      },
      "outputs": [],
      "source": [
        "adultDF.write\\\n",
        ".mode(\"overwrite\")\\\n",
        ".partitionBy(\"earnings\")\\\n",
        ".parquet(\"adult_partition\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "ez_9IVMenJ-5"
      },
      "outputs": [],
      "source": [
        "adultDF.write\\\n",
        ".format(\"parquet\")\\\n",
        ".partitionBy(\"earnings\")\\\n",
        ".saveAsTable(\"adult_partition\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "05ynxWZjnJ-5"
      },
      "outputs": [],
      "source": [
        "adultDF.write\\\n",
        ".mode(\"overwrite\")\\\n",
        ".format(\"parquet\")\\\n",
        ".bucketBy(4, \"workclass\", \"education\", \"occupation\")\\\n",
        ".saveAsTable(\"adult_bucket\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWTFIFmenJ-5",
        "outputId": "f626c67b-8e6d-4abc-f332-8150d0f5c284"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n",
            "|age|\n",
            "+---+\n",
            "| 50|\n",
            "| 28|\n",
            "| 52|\n",
            "| 31|\n",
            "| 37|\n",
            "| 23|\n",
            "| 32|\n",
            "| 25|\n",
            "| 32|\n",
            "| 54|\n",
            "+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"select age from adult_bucket limit 10\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfDrrGRTnJ-5"
      },
      "source": [
        "****"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWZK1uh7nJ-5"
      },
      "source": [
        "## Praca z DataFrame'ami"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPeqhKlbnJ-5"
      },
      "source": [
        "### Kolumny"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0qEjORunJ-5"
      },
      "source": [
        "Odwolania do poszczegolnych kolumn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGXHLQNKnJ-5",
        "outputId": "8442f4e0-8a69-407a-f30e-9e80b7e97f4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Column<'age'>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "peopleDF.age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ral58zfgnJ-6",
        "outputId": "cc87f1e6-0eaf-4d34-df2a-bc1a03b3c3bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Column<'age'>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "peopleDF['age']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HczeIMvxnJ-6"
      },
      "outputs": [],
      "source": [
        "peopleDF[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cq290viCnJ-6",
        "outputId": "70dbb8ea-812c-493b-8d9a-7071b04daa6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+\n",
            "| age|\n",
            "+----+\n",
            "|  32|\n",
            "|  24|\n",
            "|null|\n",
            "|  33|\n",
            "|null|\n",
            "|  32|\n",
            "|  40|\n",
            "+----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import \n",
        "f.col(\"age\")\n",
        "srednia = f.col(\"age\")\n",
        "peopleDF.select(average(srednia)).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFSVGU9onJ-6"
      },
      "outputs": [],
      "source": [
        "\"age\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t750sSaSnJ-6"
      },
      "source": [
        "Lista kolumn "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Iz5KxdTnJ-6"
      },
      "outputs": [],
      "source": [
        "peopleDF.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o81HR-zInJ-6"
      },
      "outputs": [],
      "source": [
        "peopleDF.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbdOosUDnJ-6"
      },
      "source": [
        "Schemat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf47J1rBnJ-6"
      },
      "outputs": [],
      "source": [
        "peopleDF.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IW3GbeBbnJ-7"
      },
      "source": [
        "### Rejestracja DF jako temp view"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5R0mTlG0nJ-7"
      },
      "outputs": [],
      "source": [
        "empHist.createOrReplaceTempView(\"empHist\")\n",
        "adultDF.createOrReplaceTempView('adultDF')\n",
        "peopleDF.createOrReplaceTempView('peopleDF')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVyo7_aznJ-7"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select * from empHist limit 10\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjOJH0oynJ-7"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select age, workclass from adultDF limit 10\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkCcBayInJ-7"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select * from peopleDF\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoJ89e21nJ-7"
      },
      "outputs": [],
      "source": [
        "# usunięcie temp view\n",
        "#spark.catalog.dropTempView(\"peopleDF\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjvPjpxPnJ-7"
      },
      "source": [
        "### Przegląd akcji i transformacji"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nOGyo8KnJ-7"
      },
      "source": [
        "----\n",
        "- **filter(cond) / where(cond)** - zwraca nowy DF z wierszami spełniającymi wskazany warunek (**T**)\n",
        "- **select(cols)** - zwraca nowy DF ze wskazanymi kolumnami (**T**)\n",
        "- **distinct()** - zwraca nowy DF z unikalnymi wierszami z oryginalnego DF (**T**)\n",
        "- **show(n, truncate, vertical)** - wyświetla `n` wierszy DF (**A**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCSKiE0gnJ-7"
      },
      "outputs": [],
      "source": [
        "empHist \\\n",
        ".where((empHist.company == \"X\") & (empHist.salary > 6000)) \\\n",
        ".select(\"name\") \\\n",
        ".distinct() \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xfv0S3ygnJ-8"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select distinct name from empHist where company = 'X' and salary > 6000\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQT1WupOnJ-8"
      },
      "outputs": [],
      "source": [
        "empHist \\\n",
        ".where((empHist.company == \"X\") & (empHist.salary > 6000)) \\\n",
        ".select(\"name\") \\\n",
        ".distinct() \\\n",
        ".explain()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OaVLS98nJ-8"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select distinct name from empHist where company = 'X' and salary > 6000\").explain()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96wvVjwLnJ-8"
      },
      "source": [
        "----\n",
        "- **withColumn(name, col)** - zwraca nowy DF zawierający nowo zdefiniowaną kolumnę (**T**)\n",
        "- **drop(cols)** - zwraca nowy DF bez wskazanych kolumn (**T**)\n",
        "- **withColumnRenamed(old, new)** - zwraca nowy DF ze zmienioną nazwą kolumny (**T**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5jjVT3MnJ-8"
      },
      "outputs": [],
      "source": [
        "empHist \\\n",
        ".withColumn(\"salary\", empHist.salary * 0.8) \\\n",
        ".drop(\"company\") \\\n",
        ".withColumnRenamed(\"name\", \"imie\") \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-XrUUMSnJ-8"
      },
      "outputs": [],
      "source": [
        "empHist \\\n",
        ".select(empHist[\"name\"].alias(\"imie\"), (empHist[\"salary\"] * 0.8).alias(\"salary\"), \"year\") \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXb4_dz7nJ-8"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select name imie, salary * 0.8 salary, year from empHist\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWJ7svu9nJ-8"
      },
      "source": [
        "----\n",
        "- **collect()** - zwraca elementy DF na driver (**A**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dh1lqZdznJ-8"
      },
      "outputs": [],
      "source": [
        "peopleDF \\\n",
        ".filter(peopleDF.age.isNotNull() | peopleDF.name.contains(\"t\")) \\\n",
        ".collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcTlvlx7nJ-9"
      },
      "outputs": [],
      "source": [
        "peopleDF \\\n",
        ".filter(peopleDF.age.isNotNull() | peopleDF.name.like(\"%t%\")) \\\n",
        ".collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abyDUlGAnJ-9"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select age, name from peopleDF where age is not null or name like '%t%'\").collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HejcwZS0nJ-9"
      },
      "source": [
        "----\n",
        "- **dropna(how, thresh, subset)** - zwraca nowy DF z usuniętymi wierszami zawierającymi braki danych (**T**)\n",
        "- **orderBy(cols, ascending)** - zwraca nowy DF z wierszami posortowanymi według wartości kolumn(y) (**T**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4-dfuTnnJ-9"
      },
      "outputs": [],
      "source": [
        "peopleDF \\\n",
        ".dropna(\"all\") \\\n",
        ".orderBy(\"age\") \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-U_o-SHnJ-9"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select age, name from peopleDF where age is not null or name is not null order by age\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBLkSfPInJ-9"
      },
      "outputs": [],
      "source": [
        "empHist.orderBy([\"name\", \"salary\"], ascending=[0,1]).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lO7ejXuYnJ-9"
      },
      "source": [
        "----\n",
        "- **fillna(value, subset)** - zwraca nowy DF z brakami danych zastąpionymi zdefiniowaną wartością/wartościami (**T**)\n",
        "- **take(n) / head(n)** - zwraca piersze `n` wierszy z DF jako lokalną kolekcję (listę) wierszy (**A**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3O8m5lEhnJ-9"
      },
      "outputs": [],
      "source": [
        "peopleDF \\\n",
        ".fillna(\"X\") \\\n",
        ".head(7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NS9NPz5snJ-9"
      },
      "outputs": [],
      "source": [
        "peopleDF \\\n",
        ".fillna({\"age\": 0, \"name\": \"X\"}) \\\n",
        ".take(7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vcNXdF_nJ-9"
      },
      "outputs": [],
      "source": [
        "peopleDF \\\n",
        ".select(f.when(peopleDF.age.isNull(),0).otherwise(peopleDF.age).alias(\"age\"), \n",
        "        f.when(peopleDF.name.isNull(),\"X\").otherwise(peopleDF.name).alias(\"name\")) \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jVgPuuxnJ--"
      },
      "outputs": [],
      "source": [
        "q = (\"select case when isnull(age) then 0 else age end age, \"\n",
        "     \"case when isnull(name) then 'X' else name end name from peopleDF\")\n",
        "spark.sql(q).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft4Ja9rQnJ--"
      },
      "source": [
        "----\n",
        "- **replace(old, new, subset)** - zwraca nowy DF z podmienionymi wartościami (**T**)\n",
        "- **union(df)** - zwraca nowy DF zawierający wszystkie wiersze z dwóch łączonych DFów (**T**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FoAMF85CnJ--"
      },
      "outputs": [],
      "source": [
        "peopleDF \\\n",
        ".replace(\"Peter\", \"Piotr\") \\\n",
        ".union(peopleDF) \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIEf2lBvnJ--"
      },
      "outputs": [],
      "source": [
        "peopleDF \\\n",
        ".replace({\"Peter\": \"Piotr\", \"Greg\": \"Grzegorz\", \"Alice\": \"Alicja\"}) \\\n",
        ".union(peopleDF) \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sko5zJTAnJ--"
      },
      "outputs": [],
      "source": [
        "# kolejność ma znaczenie\n",
        "peopleDF \\\n",
        ".select(f.when(peopleDF.name == \"Peter\", \"Piotr\").otherwise(peopleDF.name).alias(\"name\"), \"age\") \\\n",
        ".union(peopleDF) \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgN1LknEnJ--"
      },
      "outputs": [],
      "source": [
        "peopleDF \\\n",
        ".select(\"age\", f.when(peopleDF.name == \"Peter\", \"Piotr\").otherwise(peopleDF.name).alias(\"name\")) \\\n",
        ".union(peopleDF) \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k87mFPjAnJ-_"
      },
      "outputs": [],
      "source": [
        "peopleDF \\\n",
        ".select(f.when(peopleDF.name == \"Peter\", \"Piotr\").otherwise(peopleDF.name).alias(\"name\"), \"age\") \\\n",
        ".unionByName(peopleDF) \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcGxJx5hnJ-_"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select age, if(name='Peter','Piotr',name) name from peopleDF union all select * from peopleDF\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3aY7LHknJ-_"
      },
      "source": [
        "----\n",
        "- **join(other, on, how)** - zwraca nowy DF powstały na podstawie połączenia dwóch DFów w oparciu o wartości we wskazanej kolumnie/kolumnach (**T**)\n",
        "- **toPandas()** - zwraca DF jako Pandas DF (**A**)\n",
        "- **count()** - zwraca liczbę wierszy w DF (**A**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYFBSYc7nJ-_"
      },
      "outputs": [],
      "source": [
        "personDF = spark.createDataFrame([Row(surname=\"Wonder\", name=\"Alice\")])\n",
        "\n",
        "peopleDF \\\n",
        ".join(personDF, \"name\") \\\n",
        ".toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRk9ot_hnJ-_"
      },
      "outputs": [],
      "source": [
        "peopleDF \\\n",
        ".join(personDF, \"name\") \\\n",
        ".count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6iQgqVSnJ-_"
      },
      "outputs": [],
      "source": [
        "peopleDF \\\n",
        ".join(personDF, peopleDF.name == personDF.name, \"outer\") \\\n",
        ".toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCXcOvKBnJ-_"
      },
      "outputs": [],
      "source": [
        "peopleDF \\\n",
        ".join(personDF, peopleDF.name == personDF.name, \"outer\") \\\n",
        ".count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEN3-pNMnJ-_"
      },
      "outputs": [],
      "source": [
        "personDF.createOrReplaceTempView(\"personDF\")\n",
        "\n",
        "spark.sql(\"select pl.name, pl.age, p.surname from peopleDF pl inner join personDF p on pl.name = p.name\") \\\n",
        ".toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpI1IJf1nJ_A"
      },
      "outputs": [],
      "source": [
        "q = \"select pl.age, pl.name, p.name, p.surname from peopleDF pl full outer join personDF p on pl.name = p.name\"\n",
        "spark.sql(q).toPandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jN0GHb-nJ_A"
      },
      "source": [
        "----\n",
        "- **describe(cols)** - zwraca nowy DF zawierający podstawowe statystyki wszystkich lub wskazanych kolumn (**T**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vh7A3gRrnJ_A"
      },
      "outputs": [],
      "source": [
        "peopleDF \\\n",
        ".describe() \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nkjckVpnJ_A"
      },
      "outputs": [],
      "source": [
        "peopleDF \\\n",
        ".describe(\"name\") \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfSuI7q2nJ_A"
      },
      "source": [
        "----\n",
        "- **groupBy(cols)** - zwraca nowy DF pogrupowany po wskazanej kolumnie/kolumnach (nie jest to typowy DF, nie można go podejrzeć używając show) (**T**)\n",
        "- **agg(expr)** - zwraca nowy DF powstały w wyniku zastosowania wskazanych agregacji (**T**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoU8HeT1nJ_A"
      },
      "outputs": [],
      "source": [
        "# max, min, avg, count, sum\n",
        "empHist \\\n",
        ".groupBy(\"name\") \\\n",
        ".max(\"salary\") \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaIRX8OanJ_A"
      },
      "outputs": [],
      "source": [
        "empHist \\\n",
        ".groupBy(\"name\") \\\n",
        ".agg(f.max(\"salary\").alias(\"max_sal\"), f.avg(\"salary\").alias(\"avg_sal\"), f.min(\"year\").alias(\"first_year\")) \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmvgT6x9nJ_A"
      },
      "outputs": [],
      "source": [
        "empHist \\\n",
        ".agg(f.max(\"salary\").alias(\"max_sal\")) \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbGgVjTAnJ_B"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select name, max(salary) from empHist group by name\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKzuXlPRnJ_B"
      },
      "outputs": [],
      "source": [
        "q = \"select name, max(salary) max_sal, avg(salary) avg_sal, min(year) first_year from empHist group by name\"\n",
        "spark.sql(q).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Fwz0CrRnJ_B"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select max(salary) max_sal from empHist\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn0CRI1enJ_B"
      },
      "source": [
        "----\n",
        "- **coalesce(numPartitions)** - zwraca nowy DF z dokładnie `numPartitions` partycji, pozwala jedynie na zmniejszenie liczby partycji, unika shuffle (**T**)\n",
        "- **repartition(numPartitions [,cols])** - zwraca nowy DF z dokładnie `numPartitions` partycji, wywołuje shuffle, wykorzystuje funkcję hashującą (**T**)\n",
        "- **repartitionByRange(numPartitions, cols)** - zwraca nowy DF z dokładnie `numPartitions` partycji, wywołuje shuffle, wykorzystuje zakres wartości - konieczne jest wskazanie kolumny (**T**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_H3LmQ7nJ_B"
      },
      "outputs": [],
      "source": [
        "empHist.rdd.getNumPartitions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "eyaP2DnPnJ_B"
      },
      "outputs": [],
      "source": [
        "empHist.repartition(5).rdd.glom().collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89nsNNZLnJ_B"
      },
      "outputs": [],
      "source": [
        "empHist.repartition(5).rdd.glom().map(len).collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "jK3kmZrcnJ_B"
      },
      "outputs": [],
      "source": [
        "empHist.repartition(5, \"name\").rdd.glom().collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxSM-6MGnJ_B"
      },
      "outputs": [],
      "source": [
        "# spark.sql.shuffle.partitions\n",
        "empHist.repartition(\"name\").rdd.glom().collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RC3NepMnJ_B"
      },
      "outputs": [],
      "source": [
        "# spark.sql.shuffle.partitions\n",
        "empHist.groupBy(\"name\").max(\"salary\").rdd.getNumPartitions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "6JGdi-EnnJ_C"
      },
      "outputs": [],
      "source": [
        "empHist.repartitionByRange(5, \"name\").rdd.glom().collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "bNknlelqnJ_C"
      },
      "outputs": [],
      "source": [
        "empHist.repartitionByRange(\"name\").rdd.glom().collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvGhSEe6nJ_C"
      },
      "outputs": [],
      "source": [
        "empHist.repartitionByRange(5, \"name\").rdd.getNumPartitions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMLgzrsxnJ_C"
      },
      "outputs": [],
      "source": [
        "empHist.repartitionByRange(5, \"name\").rdd.glom().map(len).collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pZ3dQ9WnJ_D"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select /*+ repartition(5) */ * from empHist\").rdd.glom().collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8FwwXSRnJ_D"
      },
      "outputs": [],
      "source": [
        "# od wersji 3.0.0\n",
        "spark.sql(\"select /*+ repartition_by_range(5, name) */ * from empHist\").rdd.glom().collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7F39mXi5nJ_D"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_uYSGBDnJ_D"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZF8VfSHnJ_D"
      },
      "source": [
        "> **TODO**: Wykorzystując parametr `thresh` w dropna wyświetl DF z wierszami w których występuje maksymalnie jeden brak danych (peopleDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqrODKSGnJ_D"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH44pJ0TnJ_E"
      },
      "source": [
        "> **TODO**: Na podstawie kolumny `age` stwórz kolumnę `age_filled`, wykorzystując parametr `subset` w fillna wyświetl DF w którym braki danych w kolumnie `age_filled` zastąpione są wartością 27 (peopleDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRgcFwHRnJ_E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rv-7jZxfnJ_E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7S2Nu9QnJ_E"
      },
      "source": [
        "> **TODO**: Na podstawie kolumny `name` stwórz kolumnę `surname`, wykorzystując parametr `subset` w replace wyświetl DF w którym wartości w kolumnie `surname` zastąpione zostały w następujący sposób: Greg -> House, Alice -> Wonder, Peter -> Parker (peopleDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyuiSPFmnJ_F"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAEozaoCnJ_F"
      },
      "source": [
        "> **TODO**: Wyświetl DF zawierający średnie, maksymalne i minimalne zarobki (zaokrąglone do pełnych wartości) we wszystkich firmach w poszczególnych latach (empHist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLjfWozGnJ_F"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNtJTCzJnJ_G"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKhHWDoXnJ_G"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdMVmcnBnJ_G"
      },
      "source": [
        "### Funkcje SQL\n",
        "\n",
        "Z funkcji tych można korzystać wewnątrz transformacji: select, withColumn, agg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qXVVaVpnJ_G"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as f"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_eR6nYKnJ_H"
      },
      "source": [
        "----\n",
        "- **max(col)**\n",
        "- **min(col)**\n",
        "- **avg(col)**\n",
        "- **stddev(col)**\n",
        "- **variance(col)**\n",
        "- **count(col)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtaIV2WOnJ_I"
      },
      "outputs": [],
      "source": [
        "empHist \\\n",
        ".agg(f.max(\"salary\"), f.min(\"salary\"), f.avg(\"salary\"), \n",
        "     f.stddev(\"salary\"), f.variance(\"salary\"), f.count(\"salary\")) \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYTVTsDGnJ_I"
      },
      "outputs": [],
      "source": [
        "empHist \\\n",
        ".select(f.max(\"salary\"), f.min(\"salary\"), f.avg(\"salary\"), \n",
        "     f.stddev(\"salary\"), f.variance(\"salary\"), f.count(\"salary\")) \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goMd46ranJ_J"
      },
      "outputs": [],
      "source": [
        "q = \"select max(salary), min(salary), avg(salary), stddev(salary), variance(salary), count(salary) from empHist\"\n",
        "spark.sql(q).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uf6RxpGVnJ_J"
      },
      "source": [
        "----\n",
        "Join to popularna, ale kosztowna operacja.<br>\n",
        "W sytuacji, kiedy jeden z łaczonych DataFramow jest znacznie mniejszy (w szczegolnosci na tyle mały, że w całości mieści się w pamięci), zaleca sie zastosowanie broadcast hash join (mała tabela zostanie wysłana do każdego noda).<br>\n",
        "W niektórych przypadkach optymalizator sam za nas zdecyduje o zastosowaniu broadcast hash join.\n",
        "\n",
        "- **broadcast(df)** - oznacza DF jako dostatecznie mały do wykorzystania w broadcast joinie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tf8d0E8nJ_K"
      },
      "outputs": [],
      "source": [
        "f.broadcast(personDF)\n",
        "peopleDF \\\n",
        ".join(personDF, \"name\") \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2l13vSInJ_K"
      },
      "outputs": [],
      "source": [
        "peopleDF \\\n",
        ".join(f.broadcast(personDF), \"name\") \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZlvHmp2nJ_L"
      },
      "outputs": [],
      "source": [
        "q = (\"select /*+ broadcast(prs) */ ppl.name, ppl.age, prs.surname from \"\n",
        "     \"peopleDF ppl join personDF prs on ppl.name = prs.name\")\n",
        "\n",
        "spark.sql(q).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJT7hMBvnJ_L"
      },
      "outputs": [],
      "source": [
        "peopleDF \\\n",
        ".join(f.broadcast(personDF), \"name\") \\\n",
        ".explain()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szvmxO60nJ_L"
      },
      "outputs": [],
      "source": [
        "q = (\"select /*+ broadcast(prs) */ ppl.name, ppl.age, prs.surname from \"\n",
        "     \"peopleDF ppl join personDF prs on ppl.name = prs.name\")\n",
        "\n",
        "spark.sql(q).explain()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBi4gakWnJ_L"
      },
      "source": [
        "----\n",
        "- **lit(val)** - tworzy kolumnę ze stałą wartością\n",
        "- **asc(col)/desc(col)** - pozwalają na zdefiniowanie porządku sortowania w orderBy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7IObxiqnJ_M"
      },
      "outputs": [],
      "source": [
        "empHist \\\n",
        ".withColumn(\"const\", f.lit(12)) \\\n",
        ".orderBy(f.desc(\"year\")) \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwGtvESRnJ_M"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select name, salary, year, company, 12 const from empHist order by year desc\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNW_po--nJ_M"
      },
      "source": [
        "----\n",
        "- **col(col)** - pozwala na odwołanie się do kolumny"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb18a_z0nJ_M"
      },
      "outputs": [],
      "source": [
        "peopleDF.select(f.col(\"age\").alias(\"AGE\")).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwWQ5mIAnJ_M"
      },
      "outputs": [],
      "source": [
        "# do operacji na kolumnach potrzebne jest odwołanie do kolumny - nazwa nie wystarcza\n",
        "peopleDF.withColumn(\"X\", f.lit(3)).withColumn(\"ageX\", \"X\" * \"age\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAzNgpwInJ_M"
      },
      "outputs": [],
      "source": [
        "# peopleDF nie zawiera kolumny X\n",
        "peopleDF.withColumn(\"X\", f.lit(3)).withColumn(\"ageX\", peopleDF[\"X\"] * peopleDF[\"age\"]).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KAk0Hx3nJ_N"
      },
      "outputs": [],
      "source": [
        "peopleDF.withColumn(\"X\", f.lit(3)).withColumn(\"ageX\", f.col(\"X\") * f.col(\"age\")).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbmUX8I-nJ_N"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select age, name, 3 X, age * X ageX from peopleDF\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8hZFbXfnJ_N"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select age, name, 3 X, age * 3 ageX from peopleDF\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Lx6l9k-nJ_N"
      },
      "source": [
        "------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqob9wp3nJ_N"
      },
      "outputs": [],
      "source": [
        "t_df = spark.createDataFrame([('2019-04-27 09:00:00',), ('2019-05-09 12:00:00',), ('2019-06-01 16:30:00',)], \n",
        "                             ['time'])\n",
        "t_df.createOrReplaceTempView(\"t_df\")\n",
        "t_df.show()\n",
        "t_df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLQ4AkAlnJ_N"
      },
      "source": [
        "----------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dxJbOyYnJ_N"
      },
      "source": [
        "----\n",
        "- **split(str, pattern)** - dzieli string na podstawie wzorca (regex)\n",
        "- **explode(col)** - tworzy nowy wiersz z każdego elementu arraya"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFVfsA2-nJ_N"
      },
      "outputs": [],
      "source": [
        "t_df \\\n",
        ".select(f.explode(f.split(\"time\", \" \")).alias(\"time_exploded\")) \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJl8kEq_nJ_N"
      },
      "outputs": [],
      "source": [
        "t_df \\\n",
        ".select(f.split(\"time\", \" \").alias(\"splitted\")) \\\n",
        ".show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3S1xkRcnJ_N"
      },
      "outputs": [],
      "source": [
        "t_df \\\n",
        ".select(f.split(\"time\", \" \").alias(\"splitted\")) \\\n",
        ".printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQgeUYAenJ_N"
      },
      "outputs": [],
      "source": [
        "t_df \\\n",
        ".select(f.split(\"time\", \" \").alias(\"splitted\")) \\\n",
        ".withColumn(\"exploded\", f.explode(f.col(\"splitted\"))).show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHnC25A4nJ_N"
      },
      "outputs": [],
      "source": [
        "# dwa sposoby na wyciąganie wartości (tworzenie nowych kolumn) z kolumny zawierającej array'e\n",
        "t_df \\\n",
        ".select(f.split(\"time\", \" \").alias(\"splitted\")) \\\n",
        ".withColumn(\"date\", f.col(\"splitted\")[0]) \\\n",
        ".withColumn(\"time\", f.col(\"splitted\").getItem(1)) \\\n",
        ".show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltgx_mipnJ_O"
      },
      "outputs": [],
      "source": [
        "t_df \\\n",
        ".select(f.split(\"time\", \" \").alias(\"splitted\"), f.split(\"time\", \" \")[0].alias(\"date\"), \n",
        "        f.split(\"time\", \" \").getItem(1).alias(\"time\")) \\\n",
        ".show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYPYCy8-nJ_O"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select explode(split(time, ' ')) time_exploded from t_df\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZ-o8XU3nJ_O"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select split(time, ' ') splitted, split(time, ' ')[0] date, split(time, ' ')[1] time from t_df\") \\\n",
        ".show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5PUivTHnJ_O"
      },
      "source": [
        "----\n",
        "- **from_utc_timestamp(timestamp, tz)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dn-nNAlnJ_O"
      },
      "outputs": [],
      "source": [
        "t_df \\\n",
        ".withColumn(\"time\", f.from_utc_timestamp(\"time\", \"GMT\")) \\\n",
        ".show()\n",
        "\n",
        "t_df \\\n",
        ".withColumn(\"time\", f.from_utc_timestamp(\"time\", \"GMT\")) \\\n",
        ".dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BThc1Ms6nJ_O"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select from_utc_timestamp(time, 'GMT') time from t_df\").show()\n",
        "\n",
        "spark.sql(\"select from_utc_timestamp(time, 'GMT') time from t_df\").dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uP0ntdpBnJ_O"
      },
      "source": [
        "----\n",
        "- **lower(col)**\n",
        "- **upper(col)**\n",
        "- **length(col)**\n",
        "- **substring(str, pos, len)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEWmjcbwnJ_O"
      },
      "outputs": [],
      "source": [
        "empHist \\\n",
        ".select(f.lower(empHist.name), f.upper(empHist.name), f.length(\"name\"), f.substring(\"name\", 1, 2)) \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28_g6mXSnJ_O"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select lower(name), upper(name), length(name), substring(name, 1, 2) from empHist\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnBbyblVnJ_O"
      },
      "source": [
        "----\n",
        "- **rand(seed)**, **randn(seed)** - tworzą kolumny z losowymi wartościami z rozkładów odpowiednio jednostajnego (0-1) i normalnego (0,1)\n",
        "- **when(cond, value)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pq3nWjm-nJ_P"
      },
      "outputs": [],
      "source": [
        "peopleDF \\\n",
        ".select(f.rand(42), f.randn(1), \n",
        "        f.when(f.rand(42) > 0.7, \"U>0.7\").when(f.rand(42) > 0.4, \"U>0.4\").otherwise(\"U<=0.4\").alias(\"U\"), \n",
        "        f.when(f.randn(1) > 0.5, \"N>0.5\").otherwise(\"N<=0.5\").alias(\"N\")) \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_JwdbuinJ_P"
      },
      "outputs": [],
      "source": [
        "q = (\"select rand(42), randn(1), \"\n",
        "     \"case when rand(42) > 0.7 then 'U>0.7' when rand(42) > 0.4 then 'U>0.4' else 'U<=0.4' end U, \"\n",
        "     \"case when randn(1) > 0.5 then 'N>0.5' else 'N<=0.5' end N from peopleDF\")\n",
        "spark.sql(q).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jQaFWv8nJ_P"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7noZYZenJ_P"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CH5_OX1mnJ_P"
      },
      "source": [
        "> **TODO**: Wyświetl DF z kolumną zawierającą ostatnie dwie litery imion (empHist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65OvkF2VnJ_P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWdYAkCcnJ_P"
      },
      "source": [
        "> **TODO**: Wyświetl DF z kolumną zawierającą wartość `3` gdy imię ma 3 litery, `ok` gdy zarobki są wyższe niż 5000 oraz `?` w każdym innym przypadku (empHist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkD4lGaLnJ_P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0NKYRlanJ_S"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPh1CL90nJ_S"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBIJYEYpnJ_S"
      },
      "source": [
        "### Funkcje okienne (window functions)\n",
        "\n",
        "Służą do obliczania agregowanych wartości w grupach definiowanych oknem (window).<br>\n",
        "Zwracają wiele rekordow (tyle ile na wejsciu w grupie)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKMuvr3jnJ_T"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.window import Window"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9H4YflEnJ_T"
      },
      "source": [
        "----\n",
        "- **partitionBy(cols)** - konstruktor tworzący okna - podział DF ze względu na wartości w podanej kolumnie/kolumnach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lC1hS8L7nJ_T"
      },
      "outputs": [],
      "source": [
        "# definicja 'okna'\n",
        "windowSpec = Window.partitionBy('name')\n",
        "\n",
        "empHist \\\n",
        ".withColumn('nameCount', f.count(f.col('name')).over(windowSpec)) \\\n",
        ".show(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQMBIMzlnJ_T"
      },
      "outputs": [],
      "source": [
        "q = \"select name, salary, year, company, count(name) over (partition by name) nameCount from empHist\"\n",
        "spark.sql(q).show(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MASNmiSnJ_T"
      },
      "source": [
        "----\n",
        "- **orderBy(cols)** - definiuje wewnątrz każdego okna sortowanie w oparciu o wskazaną kolumnę/kolumny\n",
        "- **rank(), dense_rank(), row_number()** - zwracają ranking/numery wierszy w oknie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymomBsi3nJ_T"
      },
      "outputs": [],
      "source": [
        "windowSpec = Window.partitionBy(\"name\").orderBy(\"year\")\n",
        "\n",
        "empHist \\\n",
        ".withColumn(\"rank\", f.rank().over(windowSpec)) \\\n",
        ".withColumn(\"dense_rank\", f.dense_rank().over(windowSpec)) \\\n",
        ".withColumn(\"row_num\", f.row_number().over(windowSpec)) \\\n",
        ".show(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYZCeJKgnJ_T"
      },
      "outputs": [],
      "source": [
        "q = (\"select name, salary, year, company, rank() over (partition by name order by year) rank, \"\n",
        "     \"dense_rank() over (partition by name order by year) dense_rank, \"\n",
        "     \"row_number() over (partition by name order by year) row_num from empHist\")\n",
        "spark.sql(q).show(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qm1Q4pcHnJ_T"
      },
      "source": [
        "----\n",
        "- **rangeBetween(start, end)** - odaje wewnątrz każdego okna zakres (offset) na którym zastosowana zostanie wskazana funkcja (remisy w sortowaniu traktuje jak funkcja rank)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9biX7m7nJ_T"
      },
      "outputs": [],
      "source": [
        "windowSpec = Window.partitionBy(\"name\").orderBy(\"year\").rangeBetween(Window.unboundedPreceding,0)\n",
        "\n",
        "empHist \\\n",
        ".withColumn(\"moving_avg\", f.avg(f.col(\"salary\")).over(windowSpec)) \\\n",
        ".show(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdW0GXRonJ_T"
      },
      "outputs": [],
      "source": [
        "q = (\"select name, salary, year, company, avg(salary) over \"\n",
        "     \"(partition by name order by year range between unbounded preceding and current row) moving_avg \"\n",
        "     \"from empHist\")\n",
        "spark.sql(q).show(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZayyQ4OznJ_U"
      },
      "source": [
        "- **rowsBetween(start, end)** - dodaje wewnątrz każdego okna zakres (offset) na którym zastosowana zostanie wskazana funkcja (remisy w sortowaniu traktuje jak funkcja row_number)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYwdzqbjnJ_U"
      },
      "outputs": [],
      "source": [
        "windowSpec = Window.partitionBy(\"name\").orderBy(\"year\").rowsBetween(-1,1)\n",
        "\n",
        "empHist \\\n",
        ".withColumn(\"moving_avg\", f.avg(f.col(\"salary\")).over(windowSpec)) \\\n",
        ".show(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rx2kT6EvnJ_U"
      },
      "outputs": [],
      "source": [
        "q = (\"select name, salary, year, company, avg(salary) over \"\n",
        "     \"(partition by name order by year rows between 1 preceding and 1 following) moving_avg from empHist\")\n",
        "spark.sql(q).show(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmuq-y8InJ_U"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg7aRmpOnJ_U"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8FfbJ1lnJ_U"
      },
      "source": [
        "> **TODO**: Wyświetl DF z kolumną zawierającą różnicę między pensją danej osoby w konkretnym roku a średnią pensją danej osoby w analizowanym okresie (empHist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Al0sSb-4nJ_U"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMWJ5C8KnJ_U"
      },
      "source": [
        "> **TODO**: Wyświetl DF z kolumną zawierającą różnicę w pensji rok do roku dla każdej z osób - wykorzystaj funkcję `lag` (empHist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYlC7tZPnJ_U"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "An3DMNb-nJ_U"
      },
      "source": [
        "> **TODO**: Wyświetl DF z kolumną zawierającą średnią wyliczaną z dwóch poprzednich pensji dla poszczególnych osób (empHist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56u0EqPmnJ_U"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0x2NkRyEnJ_U"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDCivHYvnJ_U"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok_--PYinJ_V"
      },
      "source": [
        "### UDF - User Defined Function\n",
        "\n",
        "**NIEWYDAJNE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oakUUHgdnJ_V"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import IntegerType, StringType, FloatType"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EcFIIp3nJ_V"
      },
      "source": [
        "----\n",
        "**PRZYKŁAD 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fp66OP8ynJ_V"
      },
      "outputs": [],
      "source": [
        "def power3(value):\n",
        "    return(value**3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NE4GhRf8nJ_V"
      },
      "outputs": [],
      "source": [
        "power3(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZBMZVE6nJ_V"
      },
      "source": [
        "----\n",
        "- **udf(f, returnType)** - tworzy UDF zwracający kolumnę o wartościach typu `returnType`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kidKWuqKnJ_V"
      },
      "outputs": [],
      "source": [
        "udfPower3 = f.udf(power3, FloatType())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33DjTcnFnJ_V"
      },
      "outputs": [],
      "source": [
        "empHist.select(\"salary\", udfPower3(f.col(\"salary\")).alias(\"power3\")).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Og0bmOJMnJ_V"
      },
      "source": [
        "----\n",
        "- **SparkSession.udf.register(name, f, returnType)** - rejestruje UDF zwracający kolumnę o wartościach typu `returnType` z którego można korzystać w zapytaniach SQL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfwNPsOVnJ_V"
      },
      "outputs": [],
      "source": [
        "spark.udf.register(\"power3\", power3, FloatType())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1zEioq7nJ_V"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select salary, power3(salary) power3 from empHist\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCXwhwpvnJ_W"
      },
      "source": [
        "----\n",
        "**PRZYKŁAD 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cN-LDlz4nJ_W"
      },
      "outputs": [],
      "source": [
        "def divide(x,y):\n",
        "    return x / y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prv-o0kjnJ_W"
      },
      "outputs": [],
      "source": [
        "divide(10,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KA3DHOKZnJ_W"
      },
      "outputs": [],
      "source": [
        "udfDivide = f.udf(divide, FloatType())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Qe7Bl3XnJ_W"
      },
      "outputs": [],
      "source": [
        "empHist.select(udfDivide(f.col(\"salary\"), f.col(\"year\")).alias(\"nonsens\")).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjlD32rSnJ_W"
      },
      "outputs": [],
      "source": [
        "spark.udf.register(\"divide\", divide, FloatType())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQYlEavmnJ_W"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select divide(salary, year) nonsens from empHist\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FNZNBhHnJ_W"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_Gho_UHnJ_W"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhAIYtb1nJ_W"
      },
      "source": [
        "### ZADANIE\n",
        "[Project Gutenberg](http://www.gutenberg.org/)\n",
        "> Wstępnie przetwórz i zbadaj Moby Dicka\n",
        "1. usuń puste linie, tytuł i nazwy rozdziałów, wynik zapisz jako `textOnlyMD`\n",
        "2. policz ile słów znajduje się w tekście\n",
        "3. policz ile unikalnych słów występuje w tekście\n",
        "4. znajdź 10 najczęstszych słów\n",
        "5. sprawdź jak często wystepowało slowo \"whale\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brJLW56bnJ_W"
      },
      "outputs": [],
      "source": [
        "rawMD = spark.read.text(\"MobyDick.txt\")\n",
        "rawMD.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T828JuaEnJ_X"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6XcuaW2nJ_X"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiVEUG8JnJ_X"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBTbfJTrnJ_X"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOJ2HWdenJ_X"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
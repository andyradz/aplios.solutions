{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andyradz/aplios.solutions/blob/master/DF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGXJRQ3jnJ-s"
      },
      "source": [
        "# DataFame"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip3 install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "us3bxjElnbZX",
        "outputId": "15607936-fa3a-4c67-dac9-8d87e01de0eb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.9/dist-packages (3.4.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.9/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://drive.google.com/uc?id=1G9H9BFtcQrokludqfvDv8sz58DwT7Mn6&export=download -O data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSMpixJvxvBf",
        "outputId": "30aca400-4112-4b93-9187-d486785b8e1b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: -O: command not found\n",
            "--2023-04-14 11:55:09--  https://drive.google.com/uc?id=1G9H9BFtcQrokludqfvDv8sz58DwT7Mn6\n",
            "Resolving drive.google.com (drive.google.com)... 64.233.191.113, 64.233.191.101, 64.233.191.139, ...\n",
            "Connecting to drive.google.com (drive.google.com)|64.233.191.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-10-1o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/d71pc7qd9pvb0b6at1rkh54bkdk0va66/1681473300000/05017911732949556247/*/1G9H9BFtcQrokludqfvDv8sz58DwT7Mn6?uuid=c3b879b3-d4e5-4477-a25c-6210cf0014d9 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-04-14 11:55:14--  https://doc-10-1o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/d71pc7qd9pvb0b6at1rkh54bkdk0va66/1681473300000/05017911732949556247/*/1G9H9BFtcQrokludqfvDv8sz58DwT7Mn6?uuid=c3b879b3-d4e5-4477-a25c-6210cf0014d9\n",
            "Resolving doc-10-1o-docs.googleusercontent.com (doc-10-1o-docs.googleusercontent.com)... 142.250.136.132, 2607:f8b0:4001:c34::84\n",
            "Connecting to doc-10-1o-docs.googleusercontent.com (doc-10-1o-docs.googleusercontent.com)|142.250.136.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 25234788 (24M) [application/zip]\n",
            "Saving to: ‘uc?id=1G9H9BFtcQrokludqfvDv8sz58DwT7Mn6’\n",
            "\n",
            "uc?id=1G9H9BFtcQrok 100%[===================>]  24.07M   108MB/s    in 0.2s    \n",
            "\n",
            "2023-04-14 11:55:14 (108 MB/s) - ‘uc?id=1G9H9BFtcQrokludqfvDv8sz58DwT7Mn6’ saved [25234788/25234788]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! 7z x data.zip -o* -aoa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0T1X3JhyemJ",
        "outputId": "48216f08-f26d-4197-c784-8985107358f6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 25234788 bytes (25 MiB)\n",
            "\n",
            "Extracting archive: data.zip\n",
            "--\n",
            "Path = data.zip\n",
            "Type = zip\n",
            "Physical Size = 25234788\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b 10% - 2017-fordgobike-tripdata.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 24% - 2017-fordgobike-tripdata.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% - 2017-fordgobike-tripdata.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 44% - 2017-fordgobike-tripdata.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% - 2017-fordgobike-tripdata.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 63% - 2017-fordgobike-tripdata.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 76% 4 - Badges.xml\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 93% 4 - Badges.xml\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Folders: 1\n",
            "Files: 25\n",
            "Size:       167863139\n",
            "Compressed: 25234788\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "uNBg_33Ss1zS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa6829b3-db67-481a-e5c9-e0210dc2d897"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip freeze | grep -i spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBcik0KC-CVN",
        "outputId": "53530052-c17d-4880-a3e1-d66d83ad3ce2"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pyspark==3.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aP7Gls4fnJ-u"
      },
      "source": [
        "https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "DtLUIHQZnJ-u"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql import functions as f\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "  .config('spark.jars.packages',\n",
        "          'org.apache.iceberg:iceberg-spark-runtime-3.3_2.12:1.2.0,org.projectnessie.nessie-integrations:nessie-spark-extensions-3.3_2.12:0.54.0') \\\n",
        "  .enableHiveSupport() \\\n",
        "  .config(\"spark.executor.logs.rolling.maxRetainedFiles\", \"3\") \\\n",
        "  .config(\"spark.executor.logs.rolling.strategy\", \"size\") \\\n",
        "  .config(\"spark.executor.logs.rolling.maxSize\", \"50000\") \\\n",
        "  .appName('app') \\\n",
        "  .getOrCreate() \n",
        "\n",
        "# spark.sparkContext.stop()\n",
        "\n",
        "# from pyspark import SparkConf\n",
        "# config = SparkConf().setAll([('spark.executor.memory', '8g'),\\\n",
        "#                              ('spark.executor.cores', '3'),\\\n",
        "#                              ('spark.cores.max', '3'),\\\n",
        "#                              ('spark.driver.memory','8g')])\n",
        "\n",
        "# spark = SparkSession \\\n",
        "#         .builder.config(conf=config).getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lq5RKxIYnJ-v"
      },
      "source": [
        "## Tworzenie DataFrame'u"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwBpH-M1nJ-v"
      },
      "source": [
        "### Kolekcja Row'ów"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "XXAeMPOrnJ-v"
      },
      "outputs": [],
      "source": [
        "person1 = Row(age=32, name='Greg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUviZGecnJ-v",
        "outputId": "78fb8ea1-cb19-416b-d972-cb7147eb3f1b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(age=32, name='Greg')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "person1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQkq1lEKnJ-v",
        "outputId": "a0d94618-b266-4b09-9008-f3f4640c63fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Greg', 32)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "person1.name, person1.age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOG6GQR1nJ-w",
        "outputId": "419c1735-c75e-4743-ec4a-c9387d6d800c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "person1['age']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "R-MWZIAunJ-w",
        "outputId": "6aa39f7b-defc-491c-ee9f-26a1b213ff4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Greg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "person1[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxdwargdnJ-w",
        "outputId": "d16b077c-649b-4afd-89fa-2c58b294bd0d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "'age' in person1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "zC3otVgCnJ-w"
      },
      "outputs": [],
      "source": [
        "newPerson = Row(\"age\", \"name\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "n_zJ_D9NnJ-w"
      },
      "outputs": [],
      "source": [
        "person2 = newPerson(24, 'Alice')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpN7n1VQnJ-x",
        "outputId": "6d8dde82-e0a0-48a1-ee50-d068afd43d1c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(age=24, name='Alice')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "person2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "v7x2KzNCnJ-x"
      },
      "outputs": [],
      "source": [
        "person3 = newPerson(None, None)\n",
        "person4 = newPerson(33, None)\n",
        "person5 = newPerson(None, 'Peter')\n",
        "person6 = newPerson(32, 'Peter')\n",
        "person7 = newPerson(40, 'Greg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "stkgu5YOnJ-x"
      },
      "outputs": [],
      "source": [
        "peopleDF = spark.createDataFrame([person1, person2, person3, person4, \n",
        "                                  person5, person6, person7])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c55U2z4pnJ-x",
        "outputId": "177c80ba-f20a-417d-c92e-011de364b142"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+\n",
            "| age| name|\n",
            "+----+-----+\n",
            "|  32| Greg|\n",
            "|  24|Alice|\n",
            "|null| null|\n",
            "|  33| null|\n",
            "|null|Peter|\n",
            "|  32|Peter|\n",
            "|  40| Greg|\n",
            "+----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "peopleDF.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKSKAaawnJ-x"
      },
      "source": [
        "### Inne lokalne kolekcje"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKU5YsUenJ-x"
      },
      "source": [
        "Typy danych: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#data-types\n",
        "\n",
        "Kilka podstawowych: IntegerType, DoubleType, FloatType, StringType, BooleanType, NullType"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "eAXYvAhknJ-y"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import IntegerType, StringType, StructType, StructField"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "0B30f0rnnJ-y"
      },
      "outputs": [],
      "source": [
        "# definicja schematu\n",
        "# StructType ~ Row\n",
        "schema = StructType([StructField(\"V1\", IntegerType()), StructField(\"V2\", StringType())])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "ylB9cpKFnJ-y"
      },
      "outputs": [],
      "source": [
        "# lokalna kolekcja - lista list\n",
        "df = spark.createDataFrame([(1,2),(3,4)], schema)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgNWSKsEnJ-y",
        "outputId": "b0c9965c-c46d-4eed-a36c-5c070a6aa90f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+\n",
            "| V1| V2|\n",
            "+---+---+\n",
            "|  1|  2|\n",
            "|  3|  4|\n",
            "+---+---+\n",
            "\n",
            "root\n",
            " |-- V1: integer (nullable = true)\n",
            " |-- V2: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show()\n",
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v90q5k0CnJ-y"
      },
      "source": [
        "### RDD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkGjeHW1nJ-y"
      },
      "source": [
        "Przechodzenie RDD <-> DF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7POb6zInJ-y",
        "outputId": "e09d124a-76ab-4fa6-964c-376425474329"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "type(peopleDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvwMb0ArnJ-y",
        "outputId": "370db58a-78bf-4508-d09a-b80edae29afd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+\n",
            "| age| name|\n",
            "+----+-----+\n",
            "|  32| Greg|\n",
            "|  24|Alice|\n",
            "|null| null|\n",
            "|  33| null|\n",
            "|null|Peter|\n",
            "|  32|Peter|\n",
            "|  40| Greg|\n",
            "+----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "peopleDF.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJr0QoIEnJ-z"
      },
      "source": [
        "DF -> RDD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKrhzK9fnJ-z",
        "outputId": "b8cd8952-af61-474d-ea1d-2083bef7efe0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.rdd.RDD"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "peopleRDD = peopleDF.rdd\n",
        "type(peopleRDD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ts-3DcTcnJ-z",
        "outputId": "730f0bce-533f-4fdf-afa2-c3b6129836ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(age=32, name='Greg'),\n",
              " Row(age=24, name='Alice'),\n",
              " Row(age=None, name=None),\n",
              " Row(age=33, name=None),\n",
              " Row(age=None, name='Peter'),\n",
              " Row(age=32, name='Peter'),\n",
              " Row(age=40, name='Greg')]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "peopleRDD.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMTEaNZ8nJ-z",
        "outputId": "0315bc6c-60e5-40ae-e219-900a71791538"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(32, 'Greg'),\n",
              " (24, 'Alice'),\n",
              " (None, 'X'),\n",
              " (33, 'X'),\n",
              " (None, 'Peter'),\n",
              " (32, 'Peter'),\n",
              " (40, 'Greg')]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "peopleRDD.map(tuple).mapValues(lambda x: \"X\" if x is None else x).collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgVnJBKEnJ-0"
      },
      "source": [
        "RDD -> DF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "kEgQssi2nJ-0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af051a32-935e-40c3-f90b-5765852e755f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+\n",
            "| age| name|\n",
            "+----+-----+\n",
            "|  32| Greg|\n",
            "|  24|Alice|\n",
            "|null| null|\n",
            "|  33| null|\n",
            "|null|Peter|\n",
            "|  32|Peter|\n",
            "|  40| Greg|\n",
            "+----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "peopleRDD.toDF().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "z72j6RvbnJ-0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfcf7e30-71b5-4983-8970-b9ed9e88d291"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+\n",
            "|  _1|   _2|\n",
            "+----+-----+\n",
            "|  32| Greg|\n",
            "|  24|Alice|\n",
            "|null| null|\n",
            "|  33| null|\n",
            "|null|Peter|\n",
            "|  32|Peter|\n",
            "|  40| Greg|\n",
            "+----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "peopleRDD.map(tuple).toDF().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "yMy53TpNnJ-0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32d2c338-d94c-4b32-f657-50aedbd87b6f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('_1', 'bigint'), ('_2', 'string')]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "peopleRDD.map(tuple).toDF().dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "b5SMioxcnJ-0"
      },
      "outputs": [],
      "source": [
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "5qztecq2nJ-1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ee05f87-5f6d-4ead-e363-d10af93c91b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+\n",
            "| _1| _2|\n",
            "+---+---+\n",
            "|  0|  1|\n",
            "|  1|  2|\n",
            "|  2|  3|\n",
            "|  3|  4|\n",
            "|  4|  5|\n",
            "+---+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tupRDD = sc.parallelize([(x, x+1) for x in range(5)])\n",
        "tupRDD.toDF().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "6j821Xc1nJ-1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "outputId": "c9d2cbe6-8a25-4d0b-8d8a-75f7c35805a4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-129-370decc07d4f>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# do toDF można podać schemat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStructType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mStructField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"A\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIntegerType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStructField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStringType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtupRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36mtoDF\u001b[0;34m(self, schema, sampleRatio)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;34m+\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \"\"\"\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampleRatio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoDF\u001b[0m  \u001b[0;31m# type: ignore[assignment]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36mcreateDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m   1274\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverifySchema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m             )\n\u001b[0;32m-> 1276\u001b[0;31m         return self._create_dataframe(\n\u001b[0m\u001b[1;32m   1277\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverifySchema\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_create_dataframe\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstruct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromLocal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m         \u001b[0mjrdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerDeUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoJavaArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_java_object_rdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplySchemaToPythonRDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36m_to_java_object_rdd\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4895\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4897\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerDeUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpythonToJava\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4899\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcountApprox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfidence\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.95\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36m_jrdd\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5439\u001b[0m             \u001b[0mprofiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5441\u001b[0;31m         wrapped_func = _wrap_function(\n\u001b[0m\u001b[1;32m   5442\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prev_jrdd_deserializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofiler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5443\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36m_wrap_function\u001b[0;34m(sc, func, deserializer, serializer, profiler)\u001b[0m\n\u001b[1;32m   5239\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mserializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"serializer should not be empty\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5240\u001b[0m     \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofiler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeserializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5241\u001b[0;31m     \u001b[0mpickled_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbroadcast_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincludes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_for_python_RDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5242\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5243\u001b[0m     return sc._jvm.SimplePythonFunction(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36m_prepare_for_python_RDD\u001b[0;34m(sc, command)\u001b[0m\n\u001b[1;32m   5224\u001b[0m     \u001b[0mpickled_command\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5225\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5226\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickled_command\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetBroadcastThreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Default 1M\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5227\u001b[0m         \u001b[0;31m# The broadcast will have same life cycle as created PythonRDD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5228\u001b[0m         \u001b[0mbroadcast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickled_command\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonUtils.getBroadcastThreshold.\n: java.lang.NullPointerException\n\tat org.apache.spark.api.java.JavaSparkContext$.toSparkContext(JavaSparkContext.scala:739)\n\tat org.apache.spark.api.python.PythonUtils$.getBroadcastThreshold(PythonUtils.scala:86)\n\tat org.apache.spark.api.python.PythonUtils.getBroadcastThreshold(PythonUtils.scala)\n\tat jdk.internal.reflect.GeneratedMethodAccessor79.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
          ]
        }
      ],
      "source": [
        "# do toDF można podać schemat\n",
        "schema = StructType([StructField(\"A\", IntegerType()), StructField(\"B\", StringType())])\n",
        "tupRDD.toDF(schema).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64O617VmnJ-2"
      },
      "source": [
        "> **TODO**: Stwórz DF z 3 wierszami i 3 kolumnami - dwie typu string, jedna numeryczna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "d_8d0UK1nJ-2"
      },
      "outputs": [],
      "source": [
        "schema = StructType([StructField(\"Name\", StringType()), StructField(\"Sureame\", StringType()), StructField(\"Age\", IntegerType())])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WTLspC6nJ-2",
        "outputId": "e3da8f57-6326-4800-c66b-c12fa9d054ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+---+\n",
            "|   Name|Sureame|Age|\n",
            "+-------+-------+---+\n",
            "|Andrzej|      R| 12|\n",
            "| Hubert|      W| 34|\n",
            "| Marcin|      P| 34|\n",
            "+-------+-------+---+\n",
            "\n",
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Sureame: string (nullable = true)\n",
            " |-- Age: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "personsDF=spark.createDataFrame([('Andrzej', 'R', 12),('Hubert', 'W', 34),('Marcin', 'P', 34)], schema)\n",
        "personsDF.show()\n",
        "personsDF.printSchema()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NE5o--YnJ-2"
      },
      "source": [
        "### Plik\n",
        "\n",
        "Obsługiwane: text, csv, [nd]json, orc, parquet, avro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "OZ5Cgv3dnJ-3"
      },
      "outputs": [],
      "source": [
        "empHist = spark.read.parquet(\"data/salary_hist\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNUNuH-HnJ-3",
        "outputId": "19de3f1b-0f99-4813-d094-62030d253846"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+----+-------+\n",
            "| name| salary|year|company|\n",
            "+-----+-------+----+-------+\n",
            "|Alice|4404.23|2005|      X|\n",
            "|Alice| 3000.0|2005|      Y|\n",
            "|Alice|4780.34|2006|      X|\n",
            "|Alice|4881.72|2007|      X|\n",
            "|Alice|5280.86|2008|      X|\n",
            "|Alice|5976.68|2009|      Z|\n",
            "|Alice|6320.14|2010|      Z|\n",
            "|Betty|4138.01|2005|      Y|\n",
            "|Betty|4376.94|2006|      Y|\n",
            "|Betty|5117.68|2007|      X|\n",
            "|Betty|5630.26|2008|      X|\n",
            "|Betty|6222.57|2009|      X|\n",
            "|Betty|6623.97|2010|      X|\n",
            "|Chris|3601.42|2005|      X|\n",
            "|Chris|4015.66|2006|      X|\n",
            "|Chris|4304.73|2007|      X|\n",
            "|Chris|4650.33|2008|      X|\n",
            "|Chris|4932.86|2009|      X|\n",
            "|Chris|5869.98|2010|      X|\n",
            "|  Dan|4262.75|2005|      Y|\n",
            "+-----+-------+----+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "empHist.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBTqGvNUnJ-3",
        "outputId": "df2d0687-b166-4a25-b68f-7f8c900dcfb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "*(1) ColumnarToRow\n",
            "+- FileScan parquet [name#418,salary#419,year#420,company#421] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/content/data/salary_hist], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<name:string,salary:double,year:int,company:string>\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "empHist.explain()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0pIRnUKnJ-3",
        "outputId": "c9f15ab7-b0cf-4839-8657-6ff0bb38c657"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "*(1) ColumnarToRow\n",
            "+- FileScan parquet [name#418] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/content/data/salary_hist], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<name:string>\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "empHist.select(\"name\").explain()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4MwF8YenJ-3"
      },
      "source": [
        "Źródło danych: https://archive.ics.uci.edu/ml/datasets/adult"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! head data/adult.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBgJctLlIy2u",
        "outputId": "31f65a40-5d4f-4257-84a0-e309b3e6553a"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39, State-gov, 77516, Bachelors, 13, Never-married, Adm-clerical, Not-in-family, White, Male, 2174, 0, 40, United-States, <=50K\n",
            "50, Self-emp-not-inc, 83311, Bachelors, 13, Married-civ-spouse, Exec-managerial, Husband, White, Male, 0, 0, 13, United-States, <=50K\n",
            "38, Private, 215646, HS-grad, 9, Divorced, Handlers-cleaners, Not-in-family, White, Male, 0, 0, 40, United-States, <=50K\n",
            "53, Private, 234721, 11th, 7, Married-civ-spouse, Handlers-cleaners, Husband, Black, Male, 0, 0, 40, United-States, <=50K\n",
            "28, Private, 338409, Bachelors, 13, Married-civ-spouse, Prof-specialty, Wife, Black, Female, 0, 0, 40, Cuba, <=50K\n",
            "37, Private, 284582, Masters, 14, Married-civ-spouse, Exec-managerial, Wife, White, Female, 0, 0, 40, United-States, <=50K\n",
            "49, Private, 160187, 9th, 5, Married-spouse-absent, Other-service, Not-in-family, Black, Female, 0, 0, 16, Jamaica, <=50K\n",
            "52, Self-emp-not-inc, 209642, HS-grad, 9, Married-civ-spouse, Exec-managerial, Husband, White, Male, 0, 0, 45, United-States, >50K\n",
            "31, Private, 45781, Masters, 14, Never-married, Prof-specialty, Not-in-family, White, Female, 14084, 0, 50, United-States, >50K\n",
            "42, Private, 159449, Bachelors, 13, Married-civ-spouse, Exec-managerial, Husband, White, Male, 5178, 0, 40, United-States, >50K\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "b1O-YOIinJ-3"
      },
      "outputs": [],
      "source": [
        "# csv\n",
        "adultDF = spark.read.csv(\"data/adult.data\", inferSchema=True, ignoreLeadingWhiteSpace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1FOIwcCnJ-3",
        "outputId": "7931aaf0-5b6f-4248-8116-daf020721398"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------------+------+------------+---+--------------------+-----------------+-------------+------------------+------+-----+----+----+-------------+-----+\n",
            "|_c0|             _c1|   _c2|         _c3|_c4|                 _c5|              _c6|          _c7|               _c8|   _c9| _c10|_c11|_c12|         _c13| _c14|\n",
            "+---+----------------+------+------------+---+--------------------+-----------------+-------------+------------------+------+-----+----+----+-------------+-----+\n",
            "| 39|       State-gov| 77516|   Bachelors| 13|       Never-married|     Adm-clerical|Not-in-family|             White|  Male| 2174|   0|  40|United-States|<=50K|\n",
            "| 50|Self-emp-not-inc| 83311|   Bachelors| 13|  Married-civ-spouse|  Exec-managerial|      Husband|             White|  Male|    0|   0|  13|United-States|<=50K|\n",
            "| 38|         Private|215646|     HS-grad|  9|            Divorced|Handlers-cleaners|Not-in-family|             White|  Male|    0|   0|  40|United-States|<=50K|\n",
            "| 53|         Private|234721|        11th|  7|  Married-civ-spouse|Handlers-cleaners|      Husband|             Black|  Male|    0|   0|  40|United-States|<=50K|\n",
            "| 28|         Private|338409|   Bachelors| 13|  Married-civ-spouse|   Prof-specialty|         Wife|             Black|Female|    0|   0|  40|         Cuba|<=50K|\n",
            "| 37|         Private|284582|     Masters| 14|  Married-civ-spouse|  Exec-managerial|         Wife|             White|Female|    0|   0|  40|United-States|<=50K|\n",
            "| 49|         Private|160187|         9th|  5|Married-spouse-ab...|    Other-service|Not-in-family|             Black|Female|    0|   0|  16|      Jamaica|<=50K|\n",
            "| 52|Self-emp-not-inc|209642|     HS-grad|  9|  Married-civ-spouse|  Exec-managerial|      Husband|             White|  Male|    0|   0|  45|United-States| >50K|\n",
            "| 31|         Private| 45781|     Masters| 14|       Never-married|   Prof-specialty|Not-in-family|             White|Female|14084|   0|  50|United-States| >50K|\n",
            "| 42|         Private|159449|   Bachelors| 13|  Married-civ-spouse|  Exec-managerial|      Husband|             White|  Male| 5178|   0|  40|United-States| >50K|\n",
            "| 37|         Private|280464|Some-college| 10|  Married-civ-spouse|  Exec-managerial|      Husband|             Black|  Male|    0|   0|  80|United-States| >50K|\n",
            "| 30|       State-gov|141297|   Bachelors| 13|  Married-civ-spouse|   Prof-specialty|      Husband|Asian-Pac-Islander|  Male|    0|   0|  40|        India| >50K|\n",
            "| 23|         Private|122272|   Bachelors| 13|       Never-married|     Adm-clerical|    Own-child|             White|Female|    0|   0|  30|United-States|<=50K|\n",
            "| 32|         Private|205019|  Assoc-acdm| 12|       Never-married|            Sales|Not-in-family|             Black|  Male|    0|   0|  50|United-States|<=50K|\n",
            "| 40|         Private|121772|   Assoc-voc| 11|  Married-civ-spouse|     Craft-repair|      Husband|Asian-Pac-Islander|  Male|    0|   0|  40|            ?| >50K|\n",
            "| 34|         Private|245487|     7th-8th|  4|  Married-civ-spouse| Transport-moving|      Husband|Amer-Indian-Eskimo|  Male|    0|   0|  45|       Mexico|<=50K|\n",
            "| 25|Self-emp-not-inc|176756|     HS-grad|  9|       Never-married|  Farming-fishing|    Own-child|             White|  Male|    0|   0|  35|United-States|<=50K|\n",
            "| 32|         Private|186824|     HS-grad|  9|       Never-married|Machine-op-inspct|    Unmarried|             White|  Male|    0|   0|  40|United-States|<=50K|\n",
            "| 38|         Private| 28887|        11th|  7|  Married-civ-spouse|            Sales|      Husband|             White|  Male|    0|   0|  50|United-States|<=50K|\n",
            "| 43|Self-emp-not-inc|292175|     Masters| 14|            Divorced|  Exec-managerial|    Unmarried|             White|Female|    0|   0|  45|United-States| >50K|\n",
            "+---+----------------+------+------------+---+--------------------+-----------------+-------------+------------------+------+-----+----+----+-------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "adultDF.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXqja8dYnJ-4",
        "outputId": "a091cfad-c648-410f-b3b6-6dfee0ecc1d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(_c0=39, _c1='State-gov', _c2=77516, _c3='Bachelors', _c4=13, _c5='Never-married', _c6='Adm-clerical', _c7='Not-in-family', _c8='White', _c9='Male', _c10=2174, _c11=0, _c12=40, _c13='United-States', _c14='<=50K')]"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ],
      "source": [
        "adultDF.take(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "7XRYIWwUnJ-4"
      },
      "outputs": [],
      "source": [
        "col_names = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\",\"marital-status\", \"occupation\", \n",
        "             \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \n",
        "             \"native-country\", \"earnings\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "ts-BfwopnJ-4"
      },
      "outputs": [],
      "source": [
        "adultDF = adultDF.toDF(*col_names).drop(\"fnlwgt\").dropna(\"any\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUieVb6AnJ-4",
        "outputId": "1e780fad-8706-4334-f941-d5d8f5119a7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-RECORD 0----------------------------\n",
            " age            | 39                 \n",
            " workclass      | State-gov          \n",
            " education      | Bachelors          \n",
            " education-num  | 13                 \n",
            " marital-status | Never-married      \n",
            " occupation     | Adm-clerical       \n",
            " relationship   | Not-in-family      \n",
            " race           | White              \n",
            " sex            | Male               \n",
            " capital-gain   | 2174               \n",
            " capital-loss   | 0                  \n",
            " hours-per-week | 40                 \n",
            " native-country | United-States      \n",
            " earnings       | <=50K              \n",
            "-RECORD 1----------------------------\n",
            " age            | 50                 \n",
            " workclass      | Self-emp-not-inc   \n",
            " education      | Bachelors          \n",
            " education-num  | 13                 \n",
            " marital-status | Married-civ-spouse \n",
            " occupation     | Exec-managerial    \n",
            " relationship   | Husband            \n",
            " race           | White              \n",
            " sex            | Male               \n",
            " capital-gain   | 0                  \n",
            " capital-loss   | 0                  \n",
            " hours-per-week | 13                 \n",
            " native-country | United-States      \n",
            " earnings       | <=50K              \n",
            "-RECORD 2----------------------------\n",
            " age            | 38                 \n",
            " workclass      | Private            \n",
            " education      | HS-grad            \n",
            " education-num  | 9                  \n",
            " marital-status | Divorced           \n",
            " occupation     | Handlers-cleaners  \n",
            " relationship   | Not-in-family      \n",
            " race           | White              \n",
            " sex            | Male               \n",
            " capital-gain   | 0                  \n",
            " capital-loss   | 0                  \n",
            " hours-per-week | 40                 \n",
            " native-country | United-States      \n",
            " earnings       | <=50K              \n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "adultDF.show(3, vertical=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdB3u9ggnJ-4"
      },
      "source": [
        "## Zapisywanie DataFrame'u"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "0z-AtOzCnJ-4"
      },
      "outputs": [],
      "source": [
        "#peopleDF.write.csv(\"...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "UvMQuJAQnJ-4"
      },
      "outputs": [],
      "source": [
        "#peopleDF.write.parquet(\"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBB_oqO3nJ-4"
      },
      "source": [
        "**Partycjonowanie** - tworzenie podkatalogów w katalogu z danymi w oparciu o unikatowe wartości we wskazanej kolumnie/kolumnach - zapytania dotyczące tylko jednego z poziomów zmiennej na podstwie której dokonano partycjonowania będą musiały przeskanować jedynie fragment danych a nie całość\n",
        "\n",
        "**Bucketing** - sposób na rozdystrybuowanie/organizację danych na wskazaną (stałą) liczbę buketów, każdy bucket to osobny plik, przypisanie rekordu do bucketu wynika z hasha wartości wskazanej kolumny/kolumn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "N9zHQORfnJ-4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "outputId": "2bd3760b-6353-4acb-84b5-1f2eebcdb0be"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-137-ca47656b07f7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0madultDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"overwrite\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"earnings\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"adult_partition\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mparquet\u001b[0;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[1;32m   1654\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_opts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1656\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1658\u001b[0m     def text(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: Partition column `earnings` not found in schema struct<_c0:int,_c1:string,_c2:int,_c3:string,_c4:int,_c5:string,_c6:string,_c7:string,_c8:string,_c9:string,_c10:int,_c11:int,_c12:int,_c13:string,_c14:string>."
          ]
        }
      ],
      "source": [
        "adultDF.write\\\n",
        ".mode(\"overwrite\")\\\n",
        ".partitionBy(\"earnings\")\\\n",
        ".parquet(\"adult_partition\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "ez_9IVMenJ-5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "outputId": "3e68b824-4aa9-4dda-f814-d947bce0fdcd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-138-4e2fccc69847>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0madultDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"parquet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"earnings\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msaveAsTable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"adult_partition\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36msaveAsTable\u001b[0;34m(self, name, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m   1519\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1521\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaveAsTable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1523\u001b[0m     def json(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: partition column earnings is not defined in table spark_catalog.default.adult_partition, defined table columns are: _c0, _c1, _c2, _c3, _c4, _c5, _c6, _c7, _c8, _c9, _c10, _c11, _c12, _c13, _c14."
          ]
        }
      ],
      "source": [
        "adultDF.write\\\n",
        ".format(\"parquet\")\\\n",
        ".partitionBy(\"earnings\")\\\n",
        ".saveAsTable(\"adult_partition\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "05ynxWZjnJ-5"
      },
      "outputs": [],
      "source": [
        "adultDF.write\\\n",
        ".mode(\"overwrite\")\\\n",
        ".format(\"parquet\")\\\n",
        ".bucketBy(4, \"workclass\", \"education\", \"occupation\")\\\n",
        ".saveAsTable(\"adult_bucket\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWTFIFmenJ-5",
        "outputId": "d2c11ef4-058c-4342-8f5c-68c66c05a699"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n",
            "|age|\n",
            "+---+\n",
            "| 50|\n",
            "| 28|\n",
            "| 52|\n",
            "| 31|\n",
            "| 37|\n",
            "| 23|\n",
            "| 32|\n",
            "| 25|\n",
            "| 32|\n",
            "| 54|\n",
            "+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"select age from adult_bucket limit 10\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfDrrGRTnJ-5"
      },
      "source": [
        "****"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWZK1uh7nJ-5"
      },
      "source": [
        "## Praca z DataFrame'ami"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPeqhKlbnJ-5"
      },
      "source": [
        "### Kolumny"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0qEjORunJ-5"
      },
      "source": [
        "Odwolania do poszczegolnych kolumn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGXHLQNKnJ-5",
        "outputId": "556f3927-93ae-4afe-f807-6beec7d8854c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Column<'age'>"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ],
      "source": [
        "peopleDF.age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ral58zfgnJ-6",
        "outputId": "2fe0056f-3f7a-4568-8a4e-e8f3b789176f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Column<'age'>"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ],
      "source": [
        "peopleDF['age']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "HczeIMvxnJ-6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c59c1778-5e99-4fee-e83d-bcb0c647e693"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Column<'age'>"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ],
      "source": [
        "peopleDF[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cq290viCnJ-6",
        "outputId": "7f6315be-a479-422d-b8e3-dec7a8331137"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+\n",
            "|avg_age|\n",
            "+-------+\n",
            "|   32.2|\n",
            "+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "f.col(\"age\")\n",
        "age = f.col(\"age\")\n",
        "peopleDF.agg(f.avg(age).alias(\"avg_age\")) \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "OFSVGU9onJ-6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "310e5025-af6d-4996-9f08-a88ea9960e55"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'age'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "\"age\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t750sSaSnJ-6"
      },
      "source": [
        "Lista kolumn "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "0Iz5KxdTnJ-6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2659eae3-c806-4ee6-eff0-2b37a05dfe0d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['age', 'name']"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ],
      "source": [
        "peopleDF.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "o81HR-zInJ-6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afd46a6d-be91-4f21-8a86-d6beef7a33c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('age', 'bigint'), ('name', 'string')]"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ],
      "source": [
        "peopleDF.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbdOosUDnJ-6"
      },
      "source": [
        "Schemat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "cf47J1rBnJ-6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca571f35-17eb-4d44-e42b-0e7afa9c9d61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- age: long (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "peopleDF.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IW3GbeBbnJ-7"
      },
      "source": [
        "### Rejestracja DF jako temp view"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "5R0mTlG0nJ-7"
      },
      "outputs": [],
      "source": [
        "empHist.createOrReplaceTempView(\"empHist\")\n",
        "adultDF.createOrReplaceTempView('adultDF')\n",
        "peopleDF.createOrReplaceTempView('peopleDF')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "iVyo7_aznJ-7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0954b506-5dd9-4b97-dd54-fa7faa225e44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+----+-------+\n",
            "| name| salary|year|company|\n",
            "+-----+-------+----+-------+\n",
            "|Alice|4404.23|2005|      X|\n",
            "|Alice| 3000.0|2005|      Y|\n",
            "|Alice|4780.34|2006|      X|\n",
            "|Alice|4881.72|2007|      X|\n",
            "|Alice|5280.86|2008|      X|\n",
            "|Alice|5976.68|2009|      Z|\n",
            "|Alice|6320.14|2010|      Z|\n",
            "|Betty|4138.01|2005|      Y|\n",
            "|Betty|4376.94|2006|      Y|\n",
            "|Betty|5117.68|2007|      X|\n",
            "+-----+-------+----+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"select * from empHist limit 10\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "WjOJH0oynJ-7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "66d2f250-028f-4abf-c37d-394dd562c363"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-146-5bf69b2f8b35>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"select age, workclass from adultDF limit 10\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1438\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1439\u001b[0m             \u001b[0mlitArgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_to_java_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1440\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlitArgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1441\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1442\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `age` cannot be resolved. Did you mean one of the following? [`adultdf`.`_c0`, `adultdf`.`_c1`, `adultdf`.`_c2`, `adultdf`.`_c3`, `adultdf`.`_c4`].; line 1 pos 7;\n'GlobalLimit 10\n+- 'LocalLimit 10\n   +- 'Project ['age, 'workclass]\n      +- SubqueryAlias adultdf\n         +- View (`adultDF`, [_c0#1081,_c1#1082,_c2#1083,_c3#1084,_c4#1085,_c5#1086,_c6#1087,_c7#1088,_c8#1089,_c9#1090,_c10#1091,_c11#1092,_c12#1093,_c13#1094,_c14#1095])\n            +- Relation [_c0#1081,_c1#1082,_c2#1083,_c3#1084,_c4#1085,_c5#1086,_c6#1087,_c7#1088,_c8#1089,_c9#1090,_c10#1091,_c11#1092,_c12#1093,_c13#1094,_c14#1095] csv\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"select age, workclass from adultDF limit 10\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "nkCcBayInJ-7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1385388-9124-40bf-c269-256c755b2d8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+\n",
            "| age| name|\n",
            "+----+-----+\n",
            "|  32| Greg|\n",
            "|  24|Alice|\n",
            "|null| null|\n",
            "|  33| null|\n",
            "|null|Peter|\n",
            "|  32|Peter|\n",
            "|  40| Greg|\n",
            "+----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"select * from peopleDF\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "NoJ89e21nJ-7"
      },
      "outputs": [],
      "source": [
        "# usunięcie temp view\n",
        "#spark.catalog.dropTempView(\"peopleDF\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjvPjpxPnJ-7"
      },
      "source": [
        "### Przegląd akcji i transformacji"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nOGyo8KnJ-7"
      },
      "source": [
        "----\n",
        "- **filter(cond) / where(cond)** - zwraca nowy DF z wierszami spełniającymi wskazany warunek (**T**)\n",
        "- **select(cols)** - zwraca nowy DF ze wskazanymi kolumnami (**T**)\n",
        "- **distinct()** - zwraca nowy DF z unikalnymi wierszami z oryginalnego DF (**T**)\n",
        "- **show(n, truncate, vertical)** - wyświetla `n` wierszy DF (**A**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "RCSKiE0gnJ-7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a148c2ab-6b94-4242-f941-967aeb51790c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "| name|\n",
            "+-----+\n",
            "| Greg|\n",
            "|Betty|\n",
            "+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "empHist \\\n",
        ".where((empHist.company == \"X\") & (empHist.salary > 6000)) \\\n",
        ".select(\"name\") \\\n",
        ".distinct() \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xfv0S3ygnJ-8"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select distinct name from empHist where company = 'X' and salary > 6000\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQT1WupOnJ-8"
      },
      "outputs": [],
      "source": [
        "empHist \\\n",
        ".where((empHist.company == \"X\") & (empHist.salary > 6000)) \\\n",
        ".select(\"name\") \\\n",
        ".distinct() \\\n",
        ".explain()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OaVLS98nJ-8"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select distinct name from empHist where company = 'X' and salary > 6000\").explain()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96wvVjwLnJ-8"
      },
      "source": [
        "----\n",
        "- **withColumn(name, col)** - zwraca nowy DF zawierający nowo zdefiniowaną kolumnę (**T**)\n",
        "- **drop(cols)** - zwraca nowy DF bez wskazanych kolumn (**T**)\n",
        "- **withColumnRenamed(old, new)** - zwraca nowy DF ze zmienioną nazwą kolumny (**T**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5jjVT3MnJ-8"
      },
      "outputs": [],
      "source": [
        "empHist \\\n",
        ".withColumn(\"salary\", empHist.salary * 0.8) \\\n",
        ".drop(\"company\") \\\n",
        ".withColumnRenamed(\"name\", \"imie\") \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-XrUUMSnJ-8"
      },
      "outputs": [],
      "source": [
        "empHist \\\n",
        ".select(empHist[\"name\"].alias(\"imie\"), (empHist[\"salary\"] * 0.8).alias(\"salary\"), \"year\") \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXb4_dz7nJ-8"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select name imie, salary * 0.8 salary, year from empHist\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWJ7svu9nJ-8"
      },
      "source": [
        "----\n",
        "- **collect()** - zwraca elementy DF na driver (**A**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dh1lqZdznJ-8"
      },
      "outputs": [],
      "source": [
        "peopleDF \\\n",
        ".filter(peopleDF.age.isNotNull() | peopleDF.name.contains(\"t\")) \\\n",
        ".collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcTlvlx7nJ-9"
      },
      "outputs": [],
      "source": [
        "peopleDF \\\n",
        ".filter(peopleDF.age.isNotNull() | peopleDF.name.like(\"%t%\")) \\\n",
        ".collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abyDUlGAnJ-9"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select age, name from peopleDF where age is not null or name like '%t%'\").collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HejcwZS0nJ-9"
      },
      "source": [
        "----\n",
        "- **dropna(how, thresh, subset)** - zwraca nowy DF z usuniętymi wierszami zawierającymi braki danych (**T**)\n",
        "- **orderBy(cols, ascending)** - zwraca nowy DF z wierszami posortowanymi według wartości kolumn(y) (**T**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4-dfuTnnJ-9"
      },
      "outputs": [],
      "source": [
        "peopleDF \\\n",
        ".dropna(\"all\") \\\n",
        ".orderBy(\"age\") \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-U_o-SHnJ-9"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select age, name from peopleDF where age is not null or name is not null order by age\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBLkSfPInJ-9"
      },
      "outputs": [],
      "source": [
        "empHist.orderBy([\"name\", \"salary\"], ascending=[0,1]).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lO7ejXuYnJ-9"
      },
      "source": [
        "----\n",
        "- **fillna(value, subset)** - zwraca nowy DF z brakami danych zastąpionymi zdefiniowaną wartością/wartościami (**T**)\n",
        "- **take(n) / head(n)** - zwraca piersze `n` wierszy z DF jako lokalną kolekcję (listę) wierszy (**A**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3O8m5lEhnJ-9"
      },
      "outputs": [],
      "source": [
        "peopleDF \\\n",
        ".fillna(\"X\") \\\n",
        ".head(7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NS9NPz5snJ-9"
      },
      "outputs": [],
      "source": [
        "peopleDF \\\n",
        ".fillna({\"age\": 0, \"name\": \"X\"}) \\\n",
        ".take(7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vcNXdF_nJ-9"
      },
      "outputs": [],
      "source": [
        "peopleDF \\\n",
        ".select(f.when(peopleDF.age.isNull(),0).otherwise(peopleDF.age).alias(\"age\"), \n",
        "        f.when(peopleDF.name.isNull(),\"X\").otherwise(peopleDF.name).alias(\"name\")) \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jVgPuuxnJ--"
      },
      "outputs": [],
      "source": [
        "q = (\"select case when isnull(age) then 0 else age end age, \"\n",
        "     \"case when isnull(name) then 'X' else name end name from peopleDF\")\n",
        "spark.sql(q).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft4Ja9rQnJ--"
      },
      "source": [
        "----\n",
        "- **replace(old, new, subset)** - zwraca nowy DF z podmienionymi wartościami (**T**)\n",
        "- **union(df)** - zwraca nowy DF zawierający wszystkie wiersze z dwóch łączonych DFów (**T**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "FoAMF85CnJ--",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2de822e2-0bc1-4624-b475-87aa1316308a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+\n",
            "| age| name|\n",
            "+----+-----+\n",
            "|  32| Greg|\n",
            "|  24|Alice|\n",
            "|null| null|\n",
            "|  33| null|\n",
            "|null|Piotr|\n",
            "|  32|Piotr|\n",
            "|  40| Greg|\n",
            "|  32| Greg|\n",
            "|  24|Alice|\n",
            "|null| null|\n",
            "|  33| null|\n",
            "|null|Peter|\n",
            "|  32|Peter|\n",
            "|  40| Greg|\n",
            "+----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "peopleDF \\\n",
        ".replace(\"Peter\", \"Piotr\") \\\n",
        ".union(peopleDF) \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "VIEf2lBvnJ--",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "298910ae-d2ee-4c0f-d973-03e46cf6b952"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------+\n",
            "| age|    name|\n",
            "+----+--------+\n",
            "|  32|Grzegorz|\n",
            "|  24|  Alicja|\n",
            "|null|    null|\n",
            "|  33|    null|\n",
            "|null|   Piotr|\n",
            "|  32|   Piotr|\n",
            "|  40|Grzegorz|\n",
            "|  32|    Greg|\n",
            "|  24|   Alice|\n",
            "|null|    null|\n",
            "|  33|    null|\n",
            "|null|   Peter|\n",
            "|  32|   Peter|\n",
            "|  40|    Greg|\n",
            "+----+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "peopleDF \\\n",
        ".replace({\"Peter\": \"Piotr\", \"Greg\": \"Grzegorz\", \"Alice\": \"Alicja\"}) \\\n",
        ".union(peopleDF) \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "Sko5zJTAnJ--",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7580e0df-e0c5-40f2-8149-a4039dff0b80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+\n",
            "| name|  age|\n",
            "+-----+-----+\n",
            "| Greg|   32|\n",
            "|Alice|   24|\n",
            "| null| null|\n",
            "| null|   33|\n",
            "|Piotr| null|\n",
            "|Piotr|   32|\n",
            "| Greg|   40|\n",
            "|   32| Greg|\n",
            "|   24|Alice|\n",
            "| null| null|\n",
            "|   33| null|\n",
            "| null|Peter|\n",
            "|   32|Peter|\n",
            "|   40| Greg|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# kolejność ma znaczenie\n",
        "peopleDF \\\n",
        ".select(f.when(peopleDF.name == \"Peter\", \"Piotr\").otherwise(peopleDF.name).alias(\"name\"), \"age\") \\\n",
        ".union(peopleDF) \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgN1LknEnJ--"
      },
      "outputs": [],
      "source": [
        "peopleDF \\\n",
        ".select(\"age\", f.when(peopleDF.name == \"Peter\", \"Piotr\").otherwise(peopleDF.name).alias(\"name\")) \\\n",
        ".union(peopleDF) \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k87mFPjAnJ-_"
      },
      "outputs": [],
      "source": [
        "peopleDF \\\n",
        ".select(f.when(peopleDF.name == \"Peter\", \"Piotr\").otherwise(peopleDF.name).alias(\"name\"), \"age\") \\\n",
        ".unionByName(peopleDF) \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcGxJx5hnJ-_"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select age, if(name='Peter','Piotr',name) name from peopleDF union all select * from peopleDF\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3aY7LHknJ-_"
      },
      "source": [
        "----\n",
        "- **join(other, on, how)** - zwraca nowy DF powstały na podstawie połączenia dwóch DFów w oparciu o wartości we wskazanej kolumnie/kolumnach (**T**)\n",
        "- **toPandas()** - zwraca DF jako Pandas DF (**A**)\n",
        "- **count()** - zwraca liczbę wierszy w DF (**A**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYFBSYc7nJ-_"
      },
      "outputs": [],
      "source": [
        "personDF = spark.createDataFrame([Row(surname=\"Wonder\", name=\"Alice\")])\n",
        "\n",
        "peopleDF \\\n",
        ".join(personDF, \"name\") \\\n",
        ".toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRk9ot_hnJ-_"
      },
      "outputs": [],
      "source": [
        "peopleDF \\\n",
        ".join(personDF, \"name\") \\\n",
        ".count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6iQgqVSnJ-_"
      },
      "outputs": [],
      "source": [
        "peopleDF \\\n",
        ".join(personDF, peopleDF.name == personDF.name, \"outer\") \\\n",
        ".toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCXcOvKBnJ-_"
      },
      "outputs": [],
      "source": [
        "peopleDF \\\n",
        ".join(personDF, peopleDF.name == personDF.name, \"outer\") \\\n",
        ".count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEN3-pNMnJ-_"
      },
      "outputs": [],
      "source": [
        "personDF.createOrReplaceTempView(\"personDF\")\n",
        "\n",
        "spark.sql(\"select pl.name, pl.age, p.surname from peopleDF pl inner join personDF p on pl.name = p.name\") \\\n",
        ".toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpI1IJf1nJ_A"
      },
      "outputs": [],
      "source": [
        "q = \"select pl.age, pl.name, p.name, p.surname from peopleDF pl full outer join personDF p on pl.name = p.name\"\n",
        "spark.sql(q).toPandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jN0GHb-nJ_A"
      },
      "source": [
        "----\n",
        "- **describe(cols)** - zwraca nowy DF zawierający podstawowe statystyki wszystkich lub wskazanych kolumn (**T**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vh7A3gRrnJ_A"
      },
      "outputs": [],
      "source": [
        "peopleDF \\\n",
        ".describe() \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nkjckVpnJ_A"
      },
      "outputs": [],
      "source": [
        "peopleDF \\\n",
        ".describe(\"name\") \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfSuI7q2nJ_A"
      },
      "source": [
        "----\n",
        "- **groupBy(cols)** - zwraca nowy DF pogrupowany po wskazanej kolumnie/kolumnach (nie jest to typowy DF, nie można go podejrzeć używając show) (**T**)\n",
        "- **agg(expr)** - zwraca nowy DF powstały w wyniku zastosowania wskazanych agregacji (**T**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoU8HeT1nJ_A"
      },
      "outputs": [],
      "source": [
        "# max, min, avg, count, sum\n",
        "empHist \\\n",
        ".groupBy(\"name\") \\\n",
        ".max(\"salary\") \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaIRX8OanJ_A"
      },
      "outputs": [],
      "source": [
        "empHist \\\n",
        ".groupBy(\"name\") \\\n",
        ".agg(f.max(\"salary\").alias(\"max_sal\"), f.avg(\"salary\").alias(\"avg_sal\"), f.min(\"year\").alias(\"first_year\")) \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmvgT6x9nJ_A"
      },
      "outputs": [],
      "source": [
        "empHist \\\n",
        ".agg(f.max(\"salary\").alias(\"max_sal\")) \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbGgVjTAnJ_B"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select name, max(salary) from empHist group by name\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKzuXlPRnJ_B"
      },
      "outputs": [],
      "source": [
        "q = \"select name, max(salary) max_sal, avg(salary) avg_sal, min(year) first_year from empHist group by name\"\n",
        "spark.sql(q).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Fwz0CrRnJ_B"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select max(salary) max_sal from empHist\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn0CRI1enJ_B"
      },
      "source": [
        "----\n",
        "- **coalesce(numPartitions)** - zwraca nowy DF z dokładnie `numPartitions` partycji, pozwala jedynie na zmniejszenie liczby partycji, unika shuffle (**T**)\n",
        "- **repartition(numPartitions [,cols])** - zwraca nowy DF z dokładnie `numPartitions` partycji, wywołuje shuffle, wykorzystuje funkcję hashującą (**T**)\n",
        "- **repartitionByRange(numPartitions, cols)** - zwraca nowy DF z dokładnie `numPartitions` partycji, wywołuje shuffle, wykorzystuje zakres wartości - konieczne jest wskazanie kolumny (**T**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_H3LmQ7nJ_B"
      },
      "outputs": [],
      "source": [
        "empHist.rdd.getNumPartitions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "eyaP2DnPnJ_B"
      },
      "outputs": [],
      "source": [
        "empHist.repartition(5).rdd.glom().collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89nsNNZLnJ_B"
      },
      "outputs": [],
      "source": [
        "empHist.repartition(5).rdd.glom().map(len).collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "jK3kmZrcnJ_B"
      },
      "outputs": [],
      "source": [
        "empHist.repartition(5, \"name\").rdd.glom().collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxSM-6MGnJ_B"
      },
      "outputs": [],
      "source": [
        "# spark.sql.shuffle.partitions\n",
        "empHist.repartition(\"name\").rdd.glom().collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RC3NepMnJ_B"
      },
      "outputs": [],
      "source": [
        "# spark.sql.shuffle.partitions\n",
        "empHist.groupBy(\"name\").max(\"salary\").rdd.getNumPartitions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "6JGdi-EnnJ_C"
      },
      "outputs": [],
      "source": [
        "empHist.repartitionByRange(5, \"name\").rdd.glom().collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "bNknlelqnJ_C"
      },
      "outputs": [],
      "source": [
        "empHist.repartitionByRange(\"name\").rdd.glom().collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvGhSEe6nJ_C"
      },
      "outputs": [],
      "source": [
        "empHist.repartitionByRange(5, \"name\").rdd.getNumPartitions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMLgzrsxnJ_C"
      },
      "outputs": [],
      "source": [
        "empHist.repartitionByRange(5, \"name\").rdd.glom().map(len).collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pZ3dQ9WnJ_D"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select /*+ repartition(5) */ * from empHist\").rdd.glom().collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8FwwXSRnJ_D"
      },
      "outputs": [],
      "source": [
        "# od wersji 3.0.0\n",
        "spark.sql(\"select /*+ repartition_by_range(5, name) */ * from empHist\").rdd.glom().collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7F39mXi5nJ_D"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_uYSGBDnJ_D"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZF8VfSHnJ_D"
      },
      "source": [
        "> **TODO**: Wykorzystując parametr `thresh` w dropna wyświetl DF z wierszami w których występuje maksymalnie jeden brak danych (peopleDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "PqrODKSGnJ_D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa6f90b3-c621-4738-fadd-aa270b08aec6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+\n",
            "| age| name|\n",
            "+----+-----+\n",
            "|  32| Greg|\n",
            "|  24|Alice|\n",
            "|  33| null|\n",
            "|null|Peter|\n",
            "|  32|Peter|\n",
            "|  40| Greg|\n",
            "+----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "peopleDF.dropna(\"all\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH44pJ0TnJ_E"
      },
      "source": [
        "> **TODO**: Na podstawie kolumny `age` stwórz kolumnę `age_filled`, wykorzystując parametr `subset` w fillna wyświetl DF w którym braki danych w kolumnie `age_filled` zastąpione są wartością 27 (peopleDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "dRgcFwHRnJ_E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "924feab1-2263-4729-f354-351e4f7054d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+\n",
            "|age| name|\n",
            "+---+-----+\n",
            "| 32| Greg|\n",
            "| 24|Alice|\n",
            "| 27| null|\n",
            "| 33| null|\n",
            "| 27|Peter|\n",
            "| 32|Peter|\n",
            "| 40| Greg|\n",
            "+---+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "peopleDF.fillna({\"age\": 27}).alias('age_filled').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7S2Nu9QnJ_E"
      },
      "source": [
        "> **TODO**: Na podstawie kolumny `name` stwórz kolumnę `surname`, wykorzystując parametr `subset` w replace wyświetl DF w którym wartości w kolumnie `surname` zastąpione zostały w następujący sposób: Greg -> House, Alice -> Wonder, Peter -> Parker (peopleDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyuiSPFmnJ_F"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAEozaoCnJ_F"
      },
      "source": [
        "> **TODO**: Wyświetl DF zawierający średnie, maksymalne i minimalne zarobki (zaokrąglone do pełnych wartości) we wszystkich firmach w poszczególnych latach (empHist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLjfWozGnJ_F"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNtJTCzJnJ_G"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKhHWDoXnJ_G"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdMVmcnBnJ_G"
      },
      "source": [
        "### Funkcje SQL\n",
        "\n",
        "Z funkcji tych można korzystać wewnątrz transformacji: select, withColumn, agg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qXVVaVpnJ_G"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as f"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_eR6nYKnJ_H"
      },
      "source": [
        "----\n",
        "- **max(col)**\n",
        "- **min(col)**\n",
        "- **avg(col)**\n",
        "- **stddev(col)**\n",
        "- **variance(col)**\n",
        "- **count(col)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtaIV2WOnJ_I"
      },
      "outputs": [],
      "source": [
        "empHist \\\n",
        ".agg(f.max(\"salary\"), f.min(\"salary\"), f.avg(\"salary\"), \n",
        "     f.stddev(\"salary\"), f.variance(\"salary\"), f.count(\"salary\")) \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYTVTsDGnJ_I"
      },
      "outputs": [],
      "source": [
        "empHist \\\n",
        ".select(f.max(\"salary\"), f.min(\"salary\"), f.avg(\"salary\"), \n",
        "     f.stddev(\"salary\"), f.variance(\"salary\"), f.count(\"salary\")) \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goMd46ranJ_J"
      },
      "outputs": [],
      "source": [
        "q = \"select max(salary), min(salary), avg(salary), stddev(salary), variance(salary), count(salary) from empHist\"\n",
        "spark.sql(q).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uf6RxpGVnJ_J"
      },
      "source": [
        "----\n",
        "Join to popularna, ale kosztowna operacja.<br>\n",
        "W sytuacji, kiedy jeden z łaczonych DataFramow jest znacznie mniejszy (w szczegolnosci na tyle mały, że w całości mieści się w pamięci), zaleca sie zastosowanie broadcast hash join (mała tabela zostanie wysłana do każdego noda).<br>\n",
        "W niektórych przypadkach optymalizator sam za nas zdecyduje o zastosowaniu broadcast hash join.\n",
        "\n",
        "- **broadcast(df)** - oznacza DF jako dostatecznie mały do wykorzystania w broadcast joinie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tf8d0E8nJ_K"
      },
      "outputs": [],
      "source": [
        "f.broadcast(personDF)\n",
        "peopleDF \\\n",
        ".join(personDF, \"name\") \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2l13vSInJ_K"
      },
      "outputs": [],
      "source": [
        "peopleDF \\\n",
        ".join(f.broadcast(personDF), \"name\") \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZlvHmp2nJ_L"
      },
      "outputs": [],
      "source": [
        "q = (\"select /*+ broadcast(prs) */ ppl.name, ppl.age, prs.surname from \"\n",
        "     \"peopleDF ppl join personDF prs on ppl.name = prs.name\")\n",
        "\n",
        "spark.sql(q).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJT7hMBvnJ_L"
      },
      "outputs": [],
      "source": [
        "peopleDF \\\n",
        ".join(f.broadcast(personDF), \"name\") \\\n",
        ".explain()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szvmxO60nJ_L"
      },
      "outputs": [],
      "source": [
        "q = (\"select /*+ broadcast(prs) */ ppl.name, ppl.age, prs.surname from \"\n",
        "     \"peopleDF ppl join personDF prs on ppl.name = prs.name\")\n",
        "\n",
        "spark.sql(q).explain()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBi4gakWnJ_L"
      },
      "source": [
        "----\n",
        "- **lit(val)** - tworzy kolumnę ze stałą wartością\n",
        "- **asc(col)/desc(col)** - pozwalają na zdefiniowanie porządku sortowania w orderBy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7IObxiqnJ_M"
      },
      "outputs": [],
      "source": [
        "empHist \\\n",
        ".withColumn(\"const\", f.lit(12)) \\\n",
        ".orderBy(f.desc(\"year\")) \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwGtvESRnJ_M"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select name, salary, year, company, 12 const from empHist order by year desc\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNW_po--nJ_M"
      },
      "source": [
        "----\n",
        "- **col(col)** - pozwala na odwołanie się do kolumny"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb18a_z0nJ_M"
      },
      "outputs": [],
      "source": [
        "peopleDF.select(f.col(\"age\").alias(\"AGE\")).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwWQ5mIAnJ_M"
      },
      "outputs": [],
      "source": [
        "# do operacji na kolumnach potrzebne jest odwołanie do kolumny - nazwa nie wystarcza\n",
        "peopleDF.withColumn(\"X\", f.lit(3)).withColumn(\"ageX\", \"X\" * \"age\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAzNgpwInJ_M"
      },
      "outputs": [],
      "source": [
        "# peopleDF nie zawiera kolumny X\n",
        "peopleDF.withColumn(\"X\", f.lit(3)).withColumn(\"ageX\", peopleDF[\"X\"] * peopleDF[\"age\"]).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KAk0Hx3nJ_N"
      },
      "outputs": [],
      "source": [
        "peopleDF.withColumn(\"X\", f.lit(3)).withColumn(\"ageX\", f.col(\"X\") * f.col(\"age\")).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbmUX8I-nJ_N"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select age, name, 3 X, age * X ageX from peopleDF\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8hZFbXfnJ_N"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select age, name, 3 X, age * 3 ageX from peopleDF\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Lx6l9k-nJ_N"
      },
      "source": [
        "------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqob9wp3nJ_N"
      },
      "outputs": [],
      "source": [
        "t_df = spark.createDataFrame([('2019-04-27 09:00:00',), ('2019-05-09 12:00:00',), ('2019-06-01 16:30:00',)], \n",
        "                             ['time'])\n",
        "t_df.createOrReplaceTempView(\"t_df\")\n",
        "t_df.show()\n",
        "t_df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLQ4AkAlnJ_N"
      },
      "source": [
        "----------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dxJbOyYnJ_N"
      },
      "source": [
        "----\n",
        "- **split(str, pattern)** - dzieli string na podstawie wzorca (regex)\n",
        "- **explode(col)** - tworzy nowy wiersz z każdego elementu arraya"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFVfsA2-nJ_N"
      },
      "outputs": [],
      "source": [
        "t_df \\\n",
        ".select(f.explode(f.split(\"time\", \" \")).alias(\"time_exploded\")) \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJl8kEq_nJ_N"
      },
      "outputs": [],
      "source": [
        "t_df \\\n",
        ".select(f.split(\"time\", \" \").alias(\"splitted\")) \\\n",
        ".show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3S1xkRcnJ_N"
      },
      "outputs": [],
      "source": [
        "t_df \\\n",
        ".select(f.split(\"time\", \" \").alias(\"splitted\")) \\\n",
        ".printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQgeUYAenJ_N"
      },
      "outputs": [],
      "source": [
        "t_df \\\n",
        ".select(f.split(\"time\", \" \").alias(\"splitted\")) \\\n",
        ".withColumn(\"exploded\", f.explode(f.col(\"splitted\"))).show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHnC25A4nJ_N"
      },
      "outputs": [],
      "source": [
        "# dwa sposoby na wyciąganie wartości (tworzenie nowych kolumn) z kolumny zawierającej array'e\n",
        "t_df \\\n",
        ".select(f.split(\"time\", \" \").alias(\"splitted\")) \\\n",
        ".withColumn(\"date\", f.col(\"splitted\")[0]) \\\n",
        ".withColumn(\"time\", f.col(\"splitted\").getItem(1)) \\\n",
        ".show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltgx_mipnJ_O"
      },
      "outputs": [],
      "source": [
        "t_df \\\n",
        ".select(f.split(\"time\", \" \").alias(\"splitted\"), f.split(\"time\", \" \")[0].alias(\"date\"), \n",
        "        f.split(\"time\", \" \").getItem(1).alias(\"time\")) \\\n",
        ".show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYPYCy8-nJ_O"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select explode(split(time, ' ')) time_exploded from t_df\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZ-o8XU3nJ_O"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select split(time, ' ') splitted, split(time, ' ')[0] date, split(time, ' ')[1] time from t_df\") \\\n",
        ".show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5PUivTHnJ_O"
      },
      "source": [
        "----\n",
        "- **from_utc_timestamp(timestamp, tz)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dn-nNAlnJ_O"
      },
      "outputs": [],
      "source": [
        "t_df \\\n",
        ".withColumn(\"time\", f.from_utc_timestamp(\"time\", \"GMT\")) \\\n",
        ".show()\n",
        "\n",
        "t_df \\\n",
        ".withColumn(\"time\", f.from_utc_timestamp(\"time\", \"GMT\")) \\\n",
        ".dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BThc1Ms6nJ_O"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select from_utc_timestamp(time, 'GMT') time from t_df\").show()\n",
        "\n",
        "spark.sql(\"select from_utc_timestamp(time, 'GMT') time from t_df\").dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uP0ntdpBnJ_O"
      },
      "source": [
        "----\n",
        "- **lower(col)**\n",
        "- **upper(col)**\n",
        "- **length(col)**\n",
        "- **substring(str, pos, len)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEWmjcbwnJ_O"
      },
      "outputs": [],
      "source": [
        "empHist \\\n",
        ".select(f.lower(empHist.name), f.upper(empHist.name), f.length(\"name\"), f.substring(\"name\", 1, 2)) \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28_g6mXSnJ_O"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select lower(name), upper(name), length(name), substring(name, 1, 2) from empHist\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnBbyblVnJ_O"
      },
      "source": [
        "----\n",
        "- **rand(seed)**, **randn(seed)** - tworzą kolumny z losowymi wartościami z rozkładów odpowiednio jednostajnego (0-1) i normalnego (0,1)\n",
        "- **when(cond, value)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pq3nWjm-nJ_P"
      },
      "outputs": [],
      "source": [
        "peopleDF \\\n",
        ".select(f.rand(42), f.randn(1), \n",
        "        f.when(f.rand(42) > 0.7, \"U>0.7\").when(f.rand(42) > 0.4, \"U>0.4\").otherwise(\"U<=0.4\").alias(\"U\"), \n",
        "        f.when(f.randn(1) > 0.5, \"N>0.5\").otherwise(\"N<=0.5\").alias(\"N\")) \\\n",
        ".show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_JwdbuinJ_P"
      },
      "outputs": [],
      "source": [
        "q = (\"select rand(42), randn(1), \"\n",
        "     \"case when rand(42) > 0.7 then 'U>0.7' when rand(42) > 0.4 then 'U>0.4' else 'U<=0.4' end U, \"\n",
        "     \"case when randn(1) > 0.5 then 'N>0.5' else 'N<=0.5' end N from peopleDF\")\n",
        "spark.sql(q).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jQaFWv8nJ_P"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7noZYZenJ_P"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CH5_OX1mnJ_P"
      },
      "source": [
        "> **TODO**: Wyświetl DF z kolumną zawierającą ostatnie dwie litery imion (empHist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "id": "65OvkF2VnJ_P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0290b1f-c615-4eff-a0a0-2b933e43e7ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------------------+\n",
            "| name|substring(name, -2, 2)|\n",
            "+-----+----------------------+\n",
            "|Chris|                    is|\n",
            "|Alice|                    ce|\n",
            "|Betty|                    ty|\n",
            "|  Dan|                    an|\n",
            "| Greg|                    eg|\n",
            "+-----+----------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "empHist.select('name', f.substring('name', -2,2)).distinct().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWdYAkCcnJ_P"
      },
      "source": [
        "> **TODO**: Wyświetl DF z kolumną zawierającą wartość `3` gdy imię ma 3 litery, `ok` gdy zarobki są wyższe niż 5000 oraz `?` w każdym innym przypadku (empHist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkD4lGaLnJ_P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0NKYRlanJ_S"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPh1CL90nJ_S"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBIJYEYpnJ_S"
      },
      "source": [
        "### Funkcje okienne (window functions)\n",
        "\n",
        "Służą do obliczania agregowanych wartości w grupach definiowanych oknem (window).<br>\n",
        "Zwracają wiele rekordow (tyle ile na wejsciu w grupie)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "id": "CKMuvr3jnJ_T"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.window import Window"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9H4YflEnJ_T"
      },
      "source": [
        "----\n",
        "- **partitionBy(cols)** - konstruktor tworzący okna - podział DF ze względu na wartości w podanej kolumnie/kolumnach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "lC1hS8L7nJ_T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cff2996-49d1-4b08-cd4b-8d5c853330b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+----+-------+---------+\n",
            "| name| salary|year|company|nameCount|\n",
            "+-----+-------+----+-------+---------+\n",
            "|Alice|4404.23|2005|      X|        7|\n",
            "|Alice| 3000.0|2005|      Y|        7|\n",
            "|Alice|4780.34|2006|      X|        7|\n",
            "|Alice|4881.72|2007|      X|        7|\n",
            "|Alice|5280.86|2008|      X|        7|\n",
            "|Alice|5976.68|2009|      Z|        7|\n",
            "|Alice|6320.14|2010|      Z|        7|\n",
            "|Betty|4138.01|2005|      Y|        6|\n",
            "|Betty|4376.94|2006|      Y|        6|\n",
            "|Betty|5117.68|2007|      X|        6|\n",
            "|Betty|5630.26|2008|      X|        6|\n",
            "|Betty|6222.57|2009|      X|        6|\n",
            "|Betty|6623.97|2010|      X|        6|\n",
            "|Chris|3601.42|2005|      X|        6|\n",
            "|Chris|4015.66|2006|      X|        6|\n",
            "|Chris|4304.73|2007|      X|        6|\n",
            "|Chris|4650.33|2008|      X|        6|\n",
            "|Chris|4932.86|2009|      X|        6|\n",
            "|Chris|5869.98|2010|      X|        6|\n",
            "|  Dan|4262.75|2005|      Y|        6|\n",
            "|  Dan|4829.28|2006|      Y|        6|\n",
            "|  Dan|5204.81|2007|      Y|        6|\n",
            "|  Dan|6244.11|2008|      Z|        6|\n",
            "|  Dan|7642.18|2009|      Z|        6|\n",
            "|  Dan|9906.35|2010|      Z|        6|\n",
            "| Greg|4226.89|2005|      Y|        5|\n",
            "| Greg|4935.72|2007|      Y|        5|\n",
            "| Greg|5274.04|2008|      Y|        5|\n",
            "| Greg|6227.36|2009|      X|        5|\n",
            "| Greg|6033.33|2010|      Z|        5|\n",
            "+-----+-------+----+-------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# definicja 'okna'\n",
        "windowSpec = Window.partitionBy('name')\n",
        "\n",
        "empHist \\\n",
        ".withColumn('nameCount', f.count(f.col('name')).over(windowSpec)) \\\n",
        ".show(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQMBIMzlnJ_T"
      },
      "outputs": [],
      "source": [
        "q = \"select name, salary, year, company, count(name) over (partition by name) nameCount from empHist\"\n",
        "spark.sql(q).show(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MASNmiSnJ_T"
      },
      "source": [
        "----\n",
        "- **orderBy(cols)** - definiuje wewnątrz każdego okna sortowanie w oparciu o wskazaną kolumnę/kolumny\n",
        "- **rank(), dense_rank(), row_number()** - zwracają ranking/numery wierszy w oknie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymomBsi3nJ_T"
      },
      "outputs": [],
      "source": [
        "windowSpec = Window.partitionBy(\"name\").orderBy(\"year\")\n",
        "\n",
        "empHist \\\n",
        ".withColumn(\"rank\", f.rank().over(windowSpec)) \\\n",
        ".withColumn(\"dense_rank\", f.dense_rank().over(windowSpec)) \\\n",
        ".withColumn(\"row_num\", f.row_number().over(windowSpec)) \\\n",
        ".show(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYZCeJKgnJ_T"
      },
      "outputs": [],
      "source": [
        "q = (\"select name, salary, year, company, rank() over (partition by name order by year) rank, \"\n",
        "     \"dense_rank() over (partition by name order by year) dense_rank, \"\n",
        "     \"row_number() over (partition by name order by year) row_num from empHist\")\n",
        "spark.sql(q).show(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qm1Q4pcHnJ_T"
      },
      "source": [
        "----\n",
        "- **rangeBetween(start, end)** - odaje wewnątrz każdego okna zakres (offset) na którym zastosowana zostanie wskazana funkcja (remisy w sortowaniu traktuje jak funkcja rank)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9biX7m7nJ_T"
      },
      "outputs": [],
      "source": [
        "windowSpec = Window.partitionBy(\"name\").orderBy(\"year\").rangeBetween(Window.unboundedPreceding,0)\n",
        "\n",
        "empHist \\\n",
        ".withColumn(\"moving_avg\", f.avg(f.col(\"salary\")).over(windowSpec)) \\\n",
        ".show(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdW0GXRonJ_T"
      },
      "outputs": [],
      "source": [
        "q = (\"select name, salary, year, company, avg(salary) over \"\n",
        "     \"(partition by name order by year range between unbounded preceding and current row) moving_avg \"\n",
        "     \"from empHist\")\n",
        "spark.sql(q).show(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZayyQ4OznJ_U"
      },
      "source": [
        "- **rowsBetween(start, end)** - dodaje wewnątrz każdego okna zakres (offset) na którym zastosowana zostanie wskazana funkcja (remisy w sortowaniu traktuje jak funkcja row_number)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYwdzqbjnJ_U"
      },
      "outputs": [],
      "source": [
        "windowSpec = Window.partitionBy(\"name\").orderBy(\"year\").rowsBetween(-1,1)\n",
        "\n",
        "empHist \\\n",
        ".withColumn(\"moving_avg\", f.avg(f.col(\"salary\")).over(windowSpec)) \\\n",
        ".show(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rx2kT6EvnJ_U"
      },
      "outputs": [],
      "source": [
        "q = (\"select name, salary, year, company, avg(salary) over \"\n",
        "     \"(partition by name order by year rows between 1 preceding and 1 following) moving_avg from empHist\")\n",
        "spark.sql(q).show(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmuq-y8InJ_U"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg7aRmpOnJ_U"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8FfbJ1lnJ_U"
      },
      "source": [
        "> **TODO**: Wyświetl DF z kolumną zawierającą różnicę między pensją danej osoby w konkretnym roku a średnią pensją danej osoby w analizowanym okresie (empHist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {
        "id": "Al0sSb-4nJ_U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "147b9bbc-76a2-4ad3-9956-45275d707572"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+----+-------+------------------+------------------+\n",
            "| name| salary|year|company|        moving_avg|         substract|\n",
            "+-----+-------+----+-------+------------------+------------------+\n",
            "|Alice|4404.23|2005|      X|          3702.115| 702.1149999999998|\n",
            "|Alice| 3000.0|2005|      Y|          3702.115|-702.1149999999998|\n",
            "|Alice|4780.34|2006|      X| 4061.523333333333| 718.8166666666671|\n",
            "|Alice|4881.72|2007|      X|         4266.5725|          615.1475|\n",
            "|Alice|5280.86|2008|      X|           4469.43| 811.4299999999994|\n",
            "|Alice|5976.68|2009|      Z| 4720.638333333333| 1256.041666666667|\n",
            "|Alice|6320.14|2010|      Z| 4949.138571428572|1371.0014285714287|\n",
            "|Betty|4138.01|2005|      Y|           4138.01|               0.0|\n",
            "|Betty|4376.94|2006|      Y|          4257.475|119.46499999999924|\n",
            "|Betty|5117.68|2007|      X|           4544.21| 573.4700000000003|\n",
            "|Betty|5630.26|2008|      X|         4815.7225| 814.5375000000004|\n",
            "|Betty|6222.57|2009|      X|          5097.092|          1125.478|\n",
            "|Betty|6623.97|2010|      X| 5351.571666666667|1272.3983333333335|\n",
            "|Chris|3601.42|2005|      X|           3601.42|               0.0|\n",
            "|Chris|4015.66|2006|      X|           3808.54| 207.1199999999999|\n",
            "|Chris|4304.73|2007|      X|3973.9366666666665|330.79333333333307|\n",
            "|Chris|4650.33|2008|      X|          4143.035| 507.2950000000001|\n",
            "|Chris|4932.86|2009|      X|            4301.0| 631.8599999999997|\n",
            "|Chris|5869.98|2010|      X| 4562.496666666667|1307.4833333333327|\n",
            "|  Dan|4262.75|2005|      Y|           4262.75|               0.0|\n",
            "|  Dan|4829.28|2006|      Y| 4546.014999999999| 283.2650000000003|\n",
            "|  Dan|5204.81|2007|      Y| 4765.613333333334| 439.1966666666667|\n",
            "|  Dan|6244.11|2008|      Z|         5135.2375|1108.8724999999995|\n",
            "|  Dan|7642.18|2009|      Z|          5636.626|          2005.554|\n",
            "|  Dan|9906.35|2010|      Z| 6348.246666666667|3558.1033333333335|\n",
            "| Greg|4226.89|2005|      Y|           4226.89|               0.0|\n",
            "| Greg|4935.72|2007|      Y|          4581.305|354.41499999999996|\n",
            "| Greg|5274.04|2008|      Y| 4812.216666666667| 461.8233333333328|\n",
            "| Greg|6227.36|2009|      X|5166.0025000000005|1061.3574999999992|\n",
            "| Greg|6033.33|2010|      Z| 5339.468000000001| 693.8619999999992|\n",
            "+-----+-------+----+-------+------------------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "windowSpec = Window.partitionBy(\"name\").orderBy(\"year\")\n",
        "\n",
        "empHist \\\n",
        "  .withColumn(\"moving_avg\", f.avg(f.col(\"salary\")).over(windowSpec)) \\\n",
        "  .withColumn(\"substract\",  f.col(\"salary\") - f.col(\"moving_avg\")) \\\n",
        "  .show(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMWJ5C8KnJ_U"
      },
      "source": [
        "> **TODO**: Wyświetl DF z kolumną zawierającą różnicę w pensji rok do roku dla każdej z osób - wykorzystaj funkcję `lag` (empHist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYlC7tZPnJ_U"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "An3DMNb-nJ_U"
      },
      "source": [
        "> **TODO**: Wyświetl DF z kolumną zawierającą średnią wyliczaną z dwóch poprzednich pensji dla poszczególnych osób (empHist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {
        "id": "56u0EqPmnJ_U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff414940-a186-4d6f-908b-0e4572ca60c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+----+-------+------------------+\n",
            "| name| salary|year|company|        moving_avg|\n",
            "+-----+-------+----+-------+------------------+\n",
            "|Alice|4404.23|2005|      X|              null|\n",
            "|Alice| 3000.0|2005|      Y|              null|\n",
            "|Alice|4780.34|2006|      X|          3702.115|\n",
            "|Alice|4881.72|2007|      X| 4061.523333333333|\n",
            "|Alice|5280.86|2008|      X| 4831.030000000001|\n",
            "|Alice|5976.68|2009|      Z|           5081.29|\n",
            "|Alice|6320.14|2010|      Z|           5628.77|\n",
            "|Betty|4138.01|2005|      Y|              null|\n",
            "|Betty|4376.94|2006|      Y|           4138.01|\n",
            "|Betty|5117.68|2007|      X|          4257.475|\n",
            "|Betty|5630.26|2008|      X|4747.3099999999995|\n",
            "|Betty|6222.57|2009|      X|           5373.97|\n",
            "|Betty|6623.97|2010|      X|          5926.415|\n",
            "|Chris|3601.42|2005|      X|              null|\n",
            "|Chris|4015.66|2006|      X|           3601.42|\n",
            "|Chris|4304.73|2007|      X|           3808.54|\n",
            "|Chris|4650.33|2008|      X|          4160.195|\n",
            "|Chris|4932.86|2009|      X|           4477.53|\n",
            "|Chris|5869.98|2010|      X| 4791.594999999999|\n",
            "|  Dan|4262.75|2005|      Y|              null|\n",
            "|  Dan|4829.28|2006|      Y|           4262.75|\n",
            "|  Dan|5204.81|2007|      Y| 4546.014999999999|\n",
            "|  Dan|6244.11|2008|      Z|          5017.045|\n",
            "|  Dan|7642.18|2009|      Z|           5724.46|\n",
            "|  Dan|9906.35|2010|      Z|          6943.145|\n",
            "| Greg|4226.89|2005|      Y|              null|\n",
            "| Greg|4935.72|2007|      Y|           4226.89|\n",
            "| Greg|5274.04|2008|      Y|           4935.72|\n",
            "| Greg|6227.36|2009|      X|           5104.88|\n",
            "| Greg|6033.33|2010|      Z|            5750.7|\n",
            "+-----+-------+----+-------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "windowSpec = Window.partitionBy(\"name\").orderBy(\"year\").rangeBetween(-2,-1)\n",
        "empHist \\\n",
        "  .withColumn(\"moving_avg\", f.avg(f.col(\"salary\")).over(windowSpec)) \\\n",
        "  .show(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0x2NkRyEnJ_U"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDCivHYvnJ_U"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok_--PYinJ_V"
      },
      "source": [
        "### UDF - User Defined Function\n",
        "\n",
        "**NIEWYDAJNE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oakUUHgdnJ_V"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import IntegerType, StringType, FloatType"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EcFIIp3nJ_V"
      },
      "source": [
        "----\n",
        "**PRZYKŁAD 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fp66OP8ynJ_V"
      },
      "outputs": [],
      "source": [
        "def power3(value):\n",
        "    return(value**3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NE4GhRf8nJ_V"
      },
      "outputs": [],
      "source": [
        "power3(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZBMZVE6nJ_V"
      },
      "source": [
        "----\n",
        "- **udf(f, returnType)** - tworzy UDF zwracający kolumnę o wartościach typu `returnType`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kidKWuqKnJ_V"
      },
      "outputs": [],
      "source": [
        "udfPower3 = f.udf(power3, FloatType())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33DjTcnFnJ_V"
      },
      "outputs": [],
      "source": [
        "empHist.select(\"salary\", udfPower3(f.col(\"salary\")).alias(\"power3\")).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Og0bmOJMnJ_V"
      },
      "source": [
        "----\n",
        "- **SparkSession.udf.register(name, f, returnType)** - rejestruje UDF zwracający kolumnę o wartościach typu `returnType` z którego można korzystać w zapytaniach SQL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfwNPsOVnJ_V"
      },
      "outputs": [],
      "source": [
        "spark.udf.register(\"power3\", power3, FloatType())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1zEioq7nJ_V"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select salary, power3(salary) power3 from empHist\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCXwhwpvnJ_W"
      },
      "source": [
        "----\n",
        "**PRZYKŁAD 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cN-LDlz4nJ_W"
      },
      "outputs": [],
      "source": [
        "def divide(x,y):\n",
        "    return x / y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prv-o0kjnJ_W"
      },
      "outputs": [],
      "source": [
        "divide(10,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KA3DHOKZnJ_W"
      },
      "outputs": [],
      "source": [
        "udfDivide = f.udf(divide, FloatType())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Qe7Bl3XnJ_W"
      },
      "outputs": [],
      "source": [
        "empHist.select(udfDivide(f.col(\"salary\"), f.col(\"year\")).alias(\"nonsens\")).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjlD32rSnJ_W"
      },
      "outputs": [],
      "source": [
        "spark.udf.register(\"divide\", divide, FloatType())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQYlEavmnJ_W"
      },
      "outputs": [],
      "source": [
        "spark.sql(\"select divide(salary, year) nonsens from empHist\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FNZNBhHnJ_W"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_Gho_UHnJ_W"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhAIYtb1nJ_W"
      },
      "source": [
        "### ZADANIE\n",
        "[Project Gutenberg](http://www.gutenberg.org/)\n",
        "> Wstępnie przetwórz i zbadaj Moby Dicka\n",
        "1. usuń puste linie, tytuł i nazwy rozdziałów, wynik zapisz jako `textOnlyMD`\n",
        "2. policz ile słów znajduje się w tekście\n",
        "3. policz ile unikalnych słów występuje w tekście\n",
        "4. znajdź 10 najczęstszych słów\n",
        "5. sprawdź jak często wystepowało slowo \"whale\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brJLW56bnJ_W"
      },
      "outputs": [],
      "source": [
        "rawMD = spark.read.text(\"MobyDick.txt\")\n",
        "rawMD.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T828JuaEnJ_X"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6XcuaW2nJ_X"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiVEUG8JnJ_X"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBTbfJTrnJ_X"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "zOJ2HWdenJ_X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 670
        },
        "outputId": "c5b4a578-4bde-45b2-ced9-0cdbf8cb8699"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-161-70217ad502a3>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerDe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpythonToJava\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mJavaObj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_java_object_rdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mnbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSizeEstimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJavaObj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-161-70217ad502a3>\u001b[0m in \u001b[0;36m_to_java_object_rdd\u001b[0;34m(rdd)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \"\"\"\n\u001b[1;32m      7\u001b[0m     \u001b[0mrdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAutoBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerDe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpythonToJava\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mJavaObj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_java_object_rdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36m_jrdd\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5439\u001b[0m             \u001b[0mprofiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5441\u001b[0;31m         wrapped_func = _wrap_function(\n\u001b[0m\u001b[1;32m   5442\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prev_jrdd_deserializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofiler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5443\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36m_wrap_function\u001b[0;34m(sc, func, deserializer, serializer, profiler)\u001b[0m\n\u001b[1;32m   5239\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mserializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"serializer should not be empty\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5240\u001b[0m     \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofiler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeserializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5241\u001b[0;31m     \u001b[0mpickled_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbroadcast_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincludes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_for_python_RDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5242\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5243\u001b[0m     return sc._jvm.SimplePythonFunction(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36m_prepare_for_python_RDD\u001b[0;34m(sc, command)\u001b[0m\n\u001b[1;32m   5224\u001b[0m     \u001b[0mpickled_command\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5225\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5226\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickled_command\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetBroadcastThreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Default 1M\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5227\u001b[0m         \u001b[0;31m# The broadcast will have same life cycle as created PythonRDD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5228\u001b[0m         \u001b[0mbroadcast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickled_command\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonUtils.getBroadcastThreshold.\n: java.lang.NullPointerException\n\tat org.apache.spark.api.java.JavaSparkContext$.toSparkContext(JavaSparkContext.scala:739)\n\tat org.apache.spark.api.python.PythonUtils$.getBroadcastThreshold(PythonUtils.scala:86)\n\tat org.apache.spark.api.python.PythonUtils.getBroadcastThreshold(PythonUtils.scala)\n\tat jdk.internal.reflect.GeneratedMethodAccessor79.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
          ]
        }
      ],
      "source": [
        "from pyspark.serializers import PickleSerializer, AutoBatchedSerializer\n",
        "def _to_java_object_rdd(rdd):  \n",
        "    \"\"\" Return a JavaRDD of Object by unpickling\n",
        "    It will convert each Python object into Java object by Pyrolite, whenever the\n",
        "    RDD is serialized in batch or not.\n",
        "    \"\"\"\n",
        "    rdd = rdd._reserialize(AutoBatchedSerializer(PickleSerializer()))\n",
        "    return rdd.ctx._jvm.org.apache.spark.mllib.api.python.SerDe.pythonToJava(rdd._jrdd, True)\n",
        "\n",
        "JavaObj = _to_java_object_rdd(df.rdd)\n",
        "\n",
        "nbytes = sc._jvm.org.apache.spark.util.SizeEstimator.estimate(JavaObj)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}